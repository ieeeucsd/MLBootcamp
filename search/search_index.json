{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the IEEE ML Bootcamp Companion Website! Here you will find all of the documentation, and tutorials that accompany the workshop material and powerpoints! Here you can find extra resources, and solution code to everything that we will be covered in the workshops. Workshop Schedule # Workshop Title Date Location 1 Introduction to ML and Setup February 2 nd , 2020 WLH 2005 2 Classical ML Algorithms and NLP February 9 th , 2020 CENTER 101 2 Neural Networks and Computer Vision February 16 th , 2020 EBU-1 2315 About This bootcamp is developed by the UCSD IEEE Student Branch Website Facebook Newsletter Bootcamp Staff Dillon Hicks Angela Liu - Technical Chair Jaden Padua - Technical Chair","title":"Home"},{"location":"#welcome-to-the-ieee-ml-bootcamp-companion-website","text":"Here you will find all of the documentation, and tutorials that accompany the workshop material and powerpoints! Here you can find extra resources, and solution code to everything that we will be covered in the workshops.","title":"Welcome to the IEEE ML Bootcamp Companion Website!"},{"location":"#workshop-schedule","text":"# Workshop Title Date Location 1 Introduction to ML and Setup February 2 nd , 2020 WLH 2005 2 Classical ML Algorithms and NLP February 9 th , 2020 CENTER 101 2 Neural Networks and Computer Vision February 16 th , 2020 EBU-1 2315","title":"Workshop Schedule"},{"location":"#about","text":"This bootcamp is developed by the UCSD IEEE Student Branch Website Facebook Newsletter Bootcamp Staff Dillon Hicks Angela Liu - Technical Chair Jaden Padua - Technical Chair","title":"About"},{"location":"0. Setup/","text":"Getting Started Preface This workshop series is intended to be fast paced introduction into the theory and applications of Machine Learning. It is assumed that you have a relatively strong basis of Linear Algebra, and Programming to be able to complete this bootcamp. Just to give an overview of what you will learn (and what you won't learn this time around): ML Subjects we will cover: Classical Linear and Clustering ML Algorithms Deep Learning and Neural Networks Natural Language Processing Basics Computer Vision Basics ML Subjects we won't cover: Probabilistic Models (Naive Bayes) Ensemble Models (Random Forest, Adaboost, xgboost) Reinforcement Learning (Q Learning, Markov Decision Processes) Deployment of Machine Learning Models Question Even though we aren't covering some of the previous topics, there are extra resources and other ML information in the Additional Resources section in the sidebar. Also if you would like workshops on the previous topics, make sure to let us know! Anaconda Summary Anaconda makes it very easy to install many tools that are used widely in Machine Learning and Data Science Workflows. It includes many of the Python libraries and tools that we will use in this Bootcamp including but not limited to: Jupyter Notebook Numpy Pandas scikit-learn OpenCV Tensorflow We will be using Anaconda for the entirety of this bootcamp series for package management Follow the steps below for your following operating system to install Anaconda. https://docs.anaconda.com/anaconda/install/ Jupyter Notebook Once you have installed Anaconda on your system, launch Jupyter Notebook from Anaconda Navigator. Jupyter notebook is a program that allows us to run our Python code in our browser in the form of notebooks. These notebooks can include markdown code, display graphs and tables, and run code through cells, meaning you don't have to fully run your code everytime you make an addition. Jupyter notebook may get hard to get used to for the Jupyter novice, but will enable you to be much more productive with your Python code. Tip Jupyter notebook will open in your computer's base directory, so if you want to open Jupyter notebook in a different folder by default, follow this steps to change your Jupyter default directory: https://stackoverflow.com/questions/15680463/change-ipython-jupyter-notebook-working-directory","title":"Getting Started"},{"location":"0. Setup/#getting-started","text":"","title":"Getting Started"},{"location":"0. Setup/#preface","text":"This workshop series is intended to be fast paced introduction into the theory and applications of Machine Learning. It is assumed that you have a relatively strong basis of Linear Algebra, and Programming to be able to complete this bootcamp. Just to give an overview of what you will learn (and what you won't learn this time around): ML Subjects we will cover: Classical Linear and Clustering ML Algorithms Deep Learning and Neural Networks Natural Language Processing Basics Computer Vision Basics ML Subjects we won't cover: Probabilistic Models (Naive Bayes) Ensemble Models (Random Forest, Adaboost, xgboost) Reinforcement Learning (Q Learning, Markov Decision Processes) Deployment of Machine Learning Models Question Even though we aren't covering some of the previous topics, there are extra resources and other ML information in the Additional Resources section in the sidebar. Also if you would like workshops on the previous topics, make sure to let us know!","title":"Preface"},{"location":"0. Setup/#anaconda","text":"Summary Anaconda makes it very easy to install many tools that are used widely in Machine Learning and Data Science Workflows. It includes many of the Python libraries and tools that we will use in this Bootcamp including but not limited to: Jupyter Notebook Numpy Pandas scikit-learn OpenCV Tensorflow We will be using Anaconda for the entirety of this bootcamp series for package management Follow the steps below for your following operating system to install Anaconda. https://docs.anaconda.com/anaconda/install/","title":"Anaconda"},{"location":"0. Setup/#jupyter-notebook","text":"Once you have installed Anaconda on your system, launch Jupyter Notebook from Anaconda Navigator. Jupyter notebook is a program that allows us to run our Python code in our browser in the form of notebooks. These notebooks can include markdown code, display graphs and tables, and run code through cells, meaning you don't have to fully run your code everytime you make an addition. Jupyter notebook may get hard to get used to for the Jupyter novice, but will enable you to be much more productive with your Python code. Tip Jupyter notebook will open in your computer's base directory, so if you want to open Jupyter notebook in a different folder by default, follow this steps to change your Jupyter default directory: https://stackoverflow.com/questions/15680463/change-ipython-jupyter-notebook-working-directory","title":"Jupyter Notebook"},{"location":"1. Basics/","text":"Before we talk about any machine learning, let's talk about the main tools that we are going to be using for this workshop in the bootcamp: NumPy and Pandas Tools: NumPy and Pandas Numpy Numpy is a library that includes many tools for mathematical computations, including a computationally efficient ndarray (much faster than python lists) 1 In addition, many mathematical functions useful in linear algebra are included in NumPy with the numpy.linalg functions. These functions will prove to be pretty useful in the rest of the workshop. If you are familiar with using MATLAB from MATH18, then you should be pretty familiar with the functions that NumPy provides. Pandas Pandas is a library that includes data structures and data analysis tools for data munging and preparation. Pandas makes it relatively easy to interact and filter through data, with nice convenience functions for plotting and exporting data to SQL databases or CSV's. Faq I heard that python is a very slow language. If it's so slow, why do we use python for such intensive tasks such as Machine Learning and Data Analysis? While it is true that Python in itself is a very slow language, most of the tools that we are using to implement ML algorithms don't use Python to do calculations. Libraries such as Numpy and Tensorflow respectively have C and C++ backends 2 3 , allowing them to be very fast. You can even uses other libraries such as Intel MKL to have hardware optimized linear algebra operations in Numpy if you are especially a speed demon. Downloads Click below to download the data and starter notebook which includes a frame for you to write your code around. Click to Download Dataset Click to Download Starter Code The Challenge Say you are a data scientist working for an investment firm. A client wants to invest their money into california real estate, buying homes in a specific block to airbnb. However, none of the homes are for sale, and the people living inside the homes won't let you appraise their homes because they hate airbnb. How do you find an estimate of their home price using data available to you? The Dataset The dataset that you are given for this challenge is a dataset on California home prices. How can you use this data to predict home prices . Below is a description of the dataset and the features you are given to predict the median home value for a block. Column title Description Range* Datatype longitude A measure of how far west a house is; a higher value is farther west Longitude values range from -180 to +180 Data set min: -124.3 Data set max: -114.3 float64 latitude A measure of how far north a house is; a higher value is farther north Latitude values range from -90 to +90 Data set min: 32.5 Data set max: 42.5 float64 housingMedianAge Median age of a house within a block; a lower number is a newer building Data set min: 1.0 Data set max: 52.0 float64 totalRooms Total number of rooms within a block Data set min: 2.0 Data set max: 37937.0 float64 totalBedrooms Total number of bedrooms within a block Data set min: 1.0 Data set max: 6445.0 float64 population Total number of people residing within a block Data set min: 3.0 Data set max: 35682.0 float64 households Total number of households, a group of people residing within a home unit, for a block Data set min: 1.0 Data set max: 6082.0 float64 medianIncome Median income for households within a block of houses (measured in tens of thousands of US Dollars) Data set min: 0.5 Data set max: 15.0 float64 medianHouseValue Median house value for households within a block (measured in US Dollars) Data set min: 14999.0 Data set max: 500001.0 float64 Info Definition: Features To clarify on the use of the word \"features\" above, features are essentially the traits of data that we use to train our machine learning model . For example, when making a model that can predict home prices, we can use all the data above to help predict the median house value for a block. The housingMedianAge , medianIncome , and all the other columns except for our predictor, medianHouseValue , are our features for our model. Linear Regression : What is Regression? Regression is a powerful tool that can often be used for predicting and values from a dataset. This is often done by creating a line or function, where the evaluation of this function can be used to predict such values. For example, with the regression below, you can predict the value of skin cancer mortality from a variable, in this case state latitude. Regression is Continuous , meaning that it is trying to predict continuous values from the variables, or features that your data has. Definition Linear Regression is the process of taking a line and fitting it to data. What we mean by \"fitting\" is that that we want to make a line that \"approximates\" the data (We'll get more into what we mean by this in a bit). The example above is with two dimensions (for example, if your dataset has 1 independent variable). Essentially, we want to find the weights w for a linear equation such that we can predict the final value from input features. Here is an example of the type of equation we are trying to set up with m independent variables. w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; \\hat{y} w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; \\hat{y} Note Representing this equation in code is hard, so it is best to represent this equation in vector (array) notation We can also put or weights and input in their vector representation, [w_1 \\; w_2 \\; w_3 \\; \\dots \\; w_m] [w_1 \\; w_2 \\; w_3 \\; \\dots \\; w_m] And also our input in it's vector representation, [x_1 \\; x_2 \\; x_3 \\; \\dots \\; x_m] [x_1 \\; x_2 \\; x_3 \\; \\dots \\; x_m] And our solution to the linear equation represented as the dot product <w,x> \\; = \\; \\hat{y} <w,x> \\; = \\; \\hat{y} Keep in mind that each of these vectors have length m for the amount of features that we want our machine learning model to use But, what exactly is an \"optimal solution\", and how do we get one? Optimization Optimization is a very important mathematical field in the world of machine learning. Optimization is essentially finding the best values for a problem to either maximize or minimize an \"objective function\". The objective function is a function that we want the output values to be \"optimized\". In our case, the objective function is the loss function , which essentially gives us a measurement of how well our algorithm is doing. Loss functions vary according to the type of problem, but for our case, we are minimizing our Root Mean Square Error (RMSE) , which essentially tells us our average error from our predictions of house value, from the true value. RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} Gradient Descent Let's say we want to find the minimize a function, for example x^2 x^2 . We can easily find the minimum of this function (remember the second derivative rule in calculus?), but how can we do it for more complicated functions that are harder to differentiate like our objective function? This problem will get very hard , and very computationally intensive . To get over this hurdle of finding the exact minimum, we can instead approximate the minimum, using an algorithm called Gradient Descent . Imagine you have a ball and place it on a slope. It will move downwards, with the direction opposite of the gradient of the slope (remember the gradient is in the direction of ascent ). We can think of gradient descent as something similar. Here we will move our current approximation of the minimum, towards the gradient. When the gradient gets small enough (in other words, when the slope is near zero at a minimum) or when we have moved our approximation for enough epochs , then we set the current approximation as our final value. Illustration of Gradient Descent on 2D loss surface Moving down a 3D loss surface However, calculating the gradient of the cost function is a costly procedure, as it has to be done with each weight of your model. If we wanted to do this mathematically, we would have to calculate the equation below to find the derivative for each feature and each sample , which would kill any computer. \\frac{d}{{dx}}f\\left( x \\right) = \\mathop {\\lim }\\limits_{\\Delta \\to 0} \\frac{{f\\left( {x + \\Delta } \\right) - f\\left( x \\right)}}{\\Delta } \\frac{d}{{dx}}f\\left( x \\right) = \\mathop {\\lim }\\limits_{\\Delta \\to 0} \\frac{{f\\left( {x + \\Delta } \\right) - f\\left( x \\right)}}{\\Delta } Instead of doing that, let's simply define the gradient as the difference between our predictions from the current iteration of gradient descent and the true values, multiplied by our sample features. This will get an approximation of the change over each feature the loss. \\nabla f(X) = -X(values-predictions) \\nabla f(X) = -X(values-predictions) Here is psuedocode for Gradient Descent below, courtesy of CS231n: Gradient Descent Pseudocode 4 1 2 3 4 5 # Vanilla Gradient Descent while True : weights_grad = evaluate_gradient ( loss_fun , data , weights ) weights += - step_size * weights_grad # perform parameter update Stochastic Gradient Descent However, gradient descent has a huge drawback: it is computationally ineffecient . For every epoch, the gradient is calculated over all training samples. This is costly, and is unfeasible for most datasets. We can improve this by using Stochastic Gradient Descent (SGD) , a modification of the standard Gradient Descent algorithm. Stochastic Gradient Descent tries to solve the previous problem by only calculating the gradient for a single randomly sampled point at a time , hence the word Stochastic . Thus, this allows to update the weights of our model much quicker, allowing SGD to converge to a minima much quicker than in standard Gradient Descent. Although this optimization method is \"noisier\" it can often be much quicker to optimize a solution (illustrated below). We can reduce this use by calculating the gradient on batches of data instead of a single sample with Minibatch Gradient Descent . This can strike a balance can help reduce noise, but also allow us to still converge on our minima quickly. This noise is not always a negative trait though, as it can in fact possibly find us a more optimal solution for our regression. This additional noise can allow our solution to essentially \"hop out\" of local minima, allowing for the search of a more optimal minima. 5 This can be especially useful when you have a complicated loss landscape with many local minima, such as those for complicated neural networks 6 : Info Approximating the weights of this equation using SGD is one way to solve linear systems, but it is not the only way. One other method that may seem familiar to you is solving the closed form system of equations using linear algebra. I've linked this additional method in the Extras page . Linear Regression in Numpy Alright, let's finally do some coding! Go download the code from this repository, where you will recieve the starter code and As explained above, NumPy and Pandas are tools that every data scientist should know before they embark on solving a problem. In addition to these two, we will also use matplotlib in order to plot graphs related to the performance of our model! 1 2 3 import numpy as np import pandas as pd import matplotlib.pyplot as plt Let's also import our data as well. Load the csv into a dataframe using the function 1 pd . read_csv ( filename ) Info Definition: Dataframe One main feature of the Pandas library is the use of Dataframes. Dataframes make it very easy to filter through large datasets with different types of data. Think of Dataframes as 2D arrays where each element can have different types, or as a SQLite table that you store within your python program. Image of a dataframe that you should see in your Jupyter notebook when you import the data Data Preparation Before we start coding and creating our ML model, we have to do a fair bit of things to our data to ensure the best performance of our model. One major thing in our model is removing missing values in our data. Missing values can affect our function greatly, causing many of the mathematical functions we use to simply not work, so we should remove them! One example is when we are trying to evaluate our linear equation to predict housing values. When we are trying to calculate the prediction, if one feature is an NaN (not a number) in the dataset, we simply cannot compute the prediction! For example, for the linear equation below, when one of the values is a NaN , the output would obviously be NaN as well. w_1*NaN \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; NaN w_1*NaN \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; NaN One way to get around this is to set these features that are missing to 0, but this essentially isn't true, so it is typically best practice to remove such samples that don't have a full feature set, just so these zero's don't affect our model too much. Some useful functions for this are the functions: 1 2 3 4 5 6 #Removes rows with NaN values in the dataframe your_dataframe . dropna () ''' Keep in mind that this functions doesn't edit the original dataframe in place, it returns another dataframe, so make sure to overwrite your dataframe or initialize a new one. ''' Another technique to help us ensure our model performs well is through Normalization of our data. What we mean by normalization is changing the features of our data in set ranges so that not one feature is inherently more important than another. One simple normalization method that we can use is min/max normalization. For this, we put all of our samples in the range of 0 to 1, with 1 being the maximum value of dataset for that feature. This makes our data less sensitive to things like the effect of units for each feature so that each can be weighed more evenly when creating weights for our linear equation. The equation for min/max normalization is given by Normalized\\: Sample = \\frac{Sample}{{Maximum\\: of\\: all\\: samples}} Normalized\\: Sample = \\frac{Sample}{{Maximum\\: of\\: all\\: samples}} 1 2 3 4 5 6 7 8 #TASK: Write a function to normalize all the data in the dataframe with min/max normalization def normalize_data ( df , columns ): #Empty dataframe normalized_df = pd . DataFrame () #ENTER CODE HERE return normalized_df Info Jargon Clarification: Performance This is one thing that is really confusing to a lot of people, how do I know whether my model performs well? The truth is, there isn't really a simple way to know this, and there is a lot of different ways to measure model performance. One way to measure model performance is the accuracy I highly recommend to read up on common machine learning performance metrics, but we will be using average absolute error and mean squared error for our regression, and accuracy for our classifications. Initialization First, let's establish some numbers that we can use to modify the training of our linear regression model. These numbers are called hyperparameters Info Definition: Hyperparameters Hyperparameters define certain portions of your machine learning model, which allows you to customize certain portions of the training to get the best performance as possible. The main hyperparameters we will use during this workshop are the learning rate and the training steps Training steps are the number of times we will update our weights while we run gradient descent. For each training step of gradient descent, we will iterate through the entire dataset. Learning rate the the number that we will multiply our gradient by in each training step. This essentially allows us to decide how large each \"step\" our loss takes during each iteration of gradient descent. In order to find the best hyperparameters, one could do a \"grid search\" , where you could run your model over different combinations of your hyperparameters to get the set that has the best performance. Read more here: https://scikit-learn.org/stable/modules/grid_search.html Since hyperparameters don't matter too much for simple models like linear regression, let's just use something that looks fine. (Honestly a lot of machine learning is trying out different things and seeing if it works \ud83d\ude0a) 1 2 3 4 5 6 7 #Setting up hyperparameters \u200b #Alpha is our learning rate alpha = 0.1 \u200b #Iterations is how many times we will run our algorithm iterations = 10000 Training our Model Now that we have set up our hyperparameters, we can now go over how to train our linear regression model using gradient descent. For this part of the workshop, we are going to create a function that takes in our data, labels, and hyperparameters, and outputs a model and a list containing the mean squared error for each training step. 1 def train ( x , y , training_steps , alpha ): Let's start by initializing our training. In our function, let's define some parameters of our function to ensure that everything works correctly. First, we will set up a history list to store our mean squared error for each iteration (you will see what this is used for later). In addition let's find the amount of weights that we need in addition to the length of our dataset. Functions: 1 2 your_np_array . shape #gets the shape of your python ndarray. #For example, for an nxm ndarray, this will return a tuple containing (n,m) Here is the skeleton code for this section to get you started on the structure 1 2 3 4 5 6 #Storing our cost function, Mean Squared Error history = [] #Finding the number of weights we need and also the number of samples num_weights = #Find the number of weights for n = #Find the number of samples in the dataset Next, let's initialize our weights! Let's initialize these weights randomly so that our model can converge to a minima with a more independent start. A useful function for this is the np.random.rand() function, which creates a list of random numbers. 1 2 3 #Initializing our weights to random numbers np . random . seed ( 69420 ) weights = #initialize weights Now that we have everything set up, I'll leave this part a bit more open ended, and write the pseudocode for each part of the gradient descent loop. For your convenience, here are the equations that are used in the gradient descent loop. Error = y - \\hat{y} Error = y - \\hat{y} \\hat{y} \\; = w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_nx_n \\hat{y} \\; = w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_nx_n \\nabla =(\\frac{1}{n})(y - \\hat{y})x \\nabla =(\\frac{1}{n})(y - \\hat{y})x RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} 1 2 3 4 5 6 7 8 #iterating through each training step for i in range ( iterations ): #testing the model and find the error #finding the root mean square error of the current weights and then append it to our mse list #finding the gradient and then defining the new weights using this gradient return weights , history Testing your model Now that we have trained our model, let's see how our model performs in terms of fitting our data. Let's graph the RMSE which we stored for each training iteration of our gradient descent. Logically, the RMSE should decrease with each training step given our algorithm is working. You can use the code below to graph the RMSE that is returned from your train() function. 1 2 3 4 5 plt . title ( 'Root Mean Square Error (MSE) over each iteration' ) plt . xlabel ( 'No. of iterations' ) plt . ylabel ( 'RMSE' ) plt . plot ( history ) plt . show () We can also measure our final RMSE and average absolute error as well. We can simply take the dot product between the weights and a the inputs to make our predictions, and Linear Regression Binary Classifier Regression is continuous, so how can we turn this into something that is discrete. In other words, how can we go from our ML model predicting values, to predicting categories? In our case, how can we predict if a given sample is above a certain price? One simple way, is simply changing your prediction value from a continuous variable, to a discrete variable. In other words, we can simply change our y values from something that is continuous, to something that is categorical. We can apply a value of 1 for each \"true\" value, and a value of -1 for each \"false\" value. To get classifications after training our classifier, we can then simply get the sign of our output to receive a positive or negative classification Danger Although this is a simple way of creating a classifier, this isn't be best way to create such a classifier. Here is an example given by Andrew Ng: For the problem listed below, of classifying malignant tumors from tumor size, we can see below that the classifier can perform very well since we can simply say that those with a value above 0.5 are malignant, and those below 0.5 are not. However, what if we introduced an outlier sample that has an extremely large tumor size compared to previously malignant samples? Then we can definitely expect that this classifier would perform poorly. As the line that is fitted to our data would predict many of the tumors to be not malignant. This is one issue with using a linear regression model as a classifier, as it is fairly prone to outliers compared to other classification methods. There are many other ways to do such a classification, as we will be making these algorithms in the next workshop, where we get more into classification! One way of doing this is by using a logistic function, or by creating a hyperplane, such that the definition between malignant and nonmalignant is very clear. Source: Stackexchange In the future, we will go over multi-class classification problems (when you are trying to distinguish between more than 2 classes), but for now we will focus on binary classification. Conclusion So in conclusion, we learned a few things from this workshop What Regression is and how you can apply it to real world challenges Basics of optimization, including Gradient Descent and its modifications How classification models are made and how you can use them Python ndarrays vs. Lists https://webcourses.ucf.edu/courses/1249560/pages/python-lists-vs-numpy-arrays-what-is-the-difference \u21a9 Numpy Internals https://docs.scipy.org/doc/numpy-1.13.0/reference/internals.html \u21a9 Tensorflow Core C++ API https://www.tensorflow.org/api_docs/cc/group/core \u21a9 CS231n: Optimization http://cs231n.github.io/optimization-1/#optimization \u21a9 SGD and Local Minima https://leon.bottou.org/publications/pdf/nimes-1991.pdf \u21a9 Neural Network Loss Landscapes https://www.cs.umd.edu/~tomg/projects/landscapes/ \u21a9","title":"1. Basics"},{"location":"1. Basics/#tools-numpy-and-pandas","text":"","title":"Tools: NumPy and Pandas"},{"location":"1. Basics/#numpy","text":"Numpy is a library that includes many tools for mathematical computations, including a computationally efficient ndarray (much faster than python lists) 1 In addition, many mathematical functions useful in linear algebra are included in NumPy with the numpy.linalg functions. These functions will prove to be pretty useful in the rest of the workshop. If you are familiar with using MATLAB from MATH18, then you should be pretty familiar with the functions that NumPy provides.","title":"Numpy"},{"location":"1. Basics/#pandas","text":"Pandas is a library that includes data structures and data analysis tools for data munging and preparation. Pandas makes it relatively easy to interact and filter through data, with nice convenience functions for plotting and exporting data to SQL databases or CSV's. Faq I heard that python is a very slow language. If it's so slow, why do we use python for such intensive tasks such as Machine Learning and Data Analysis? While it is true that Python in itself is a very slow language, most of the tools that we are using to implement ML algorithms don't use Python to do calculations. Libraries such as Numpy and Tensorflow respectively have C and C++ backends 2 3 , allowing them to be very fast. You can even uses other libraries such as Intel MKL to have hardware optimized linear algebra operations in Numpy if you are especially a speed demon.","title":"Pandas"},{"location":"1. Basics/#downloads","text":"Click below to download the data and starter notebook which includes a frame for you to write your code around. Click to Download Dataset Click to Download Starter Code","title":"Downloads"},{"location":"1. Basics/#the-challenge","text":"Say you are a data scientist working for an investment firm. A client wants to invest their money into california real estate, buying homes in a specific block to airbnb. However, none of the homes are for sale, and the people living inside the homes won't let you appraise their homes because they hate airbnb. How do you find an estimate of their home price using data available to you?","title":"The Challenge"},{"location":"1. Basics/#the-dataset","text":"The dataset that you are given for this challenge is a dataset on California home prices. How can you use this data to predict home prices . Below is a description of the dataset and the features you are given to predict the median home value for a block. Column title Description Range* Datatype longitude A measure of how far west a house is; a higher value is farther west Longitude values range from -180 to +180 Data set min: -124.3 Data set max: -114.3 float64 latitude A measure of how far north a house is; a higher value is farther north Latitude values range from -90 to +90 Data set min: 32.5 Data set max: 42.5 float64 housingMedianAge Median age of a house within a block; a lower number is a newer building Data set min: 1.0 Data set max: 52.0 float64 totalRooms Total number of rooms within a block Data set min: 2.0 Data set max: 37937.0 float64 totalBedrooms Total number of bedrooms within a block Data set min: 1.0 Data set max: 6445.0 float64 population Total number of people residing within a block Data set min: 3.0 Data set max: 35682.0 float64 households Total number of households, a group of people residing within a home unit, for a block Data set min: 1.0 Data set max: 6082.0 float64 medianIncome Median income for households within a block of houses (measured in tens of thousands of US Dollars) Data set min: 0.5 Data set max: 15.0 float64 medianHouseValue Median house value for households within a block (measured in US Dollars) Data set min: 14999.0 Data set max: 500001.0 float64 Info Definition: Features To clarify on the use of the word \"features\" above, features are essentially the traits of data that we use to train our machine learning model . For example, when making a model that can predict home prices, we can use all the data above to help predict the median house value for a block. The housingMedianAge , medianIncome , and all the other columns except for our predictor, medianHouseValue , are our features for our model.","title":"The Dataset"},{"location":"1. Basics/#linear-regression","text":"","title":"Linear Regression:"},{"location":"1. Basics/#what-is-regression","text":"Regression is a powerful tool that can often be used for predicting and values from a dataset. This is often done by creating a line or function, where the evaluation of this function can be used to predict such values. For example, with the regression below, you can predict the value of skin cancer mortality from a variable, in this case state latitude. Regression is Continuous , meaning that it is trying to predict continuous values from the variables, or features that your data has.","title":"What is Regression?"},{"location":"1. Basics/#definition","text":"Linear Regression is the process of taking a line and fitting it to data. What we mean by \"fitting\" is that that we want to make a line that \"approximates\" the data (We'll get more into what we mean by this in a bit). The example above is with two dimensions (for example, if your dataset has 1 independent variable). Essentially, we want to find the weights w for a linear equation such that we can predict the final value from input features. Here is an example of the type of equation we are trying to set up with m independent variables. w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; \\hat{y} w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; \\hat{y} Note Representing this equation in code is hard, so it is best to represent this equation in vector (array) notation We can also put or weights and input in their vector representation, [w_1 \\; w_2 \\; w_3 \\; \\dots \\; w_m] [w_1 \\; w_2 \\; w_3 \\; \\dots \\; w_m] And also our input in it's vector representation, [x_1 \\; x_2 \\; x_3 \\; \\dots \\; x_m] [x_1 \\; x_2 \\; x_3 \\; \\dots \\; x_m] And our solution to the linear equation represented as the dot product <w,x> \\; = \\; \\hat{y} <w,x> \\; = \\; \\hat{y} Keep in mind that each of these vectors have length m for the amount of features that we want our machine learning model to use But, what exactly is an \"optimal solution\", and how do we get one?","title":"Definition"},{"location":"1. Basics/#optimization","text":"Optimization is a very important mathematical field in the world of machine learning. Optimization is essentially finding the best values for a problem to either maximize or minimize an \"objective function\". The objective function is a function that we want the output values to be \"optimized\". In our case, the objective function is the loss function , which essentially gives us a measurement of how well our algorithm is doing. Loss functions vary according to the type of problem, but for our case, we are minimizing our Root Mean Square Error (RMSE) , which essentially tells us our average error from our predictions of house value, from the true value. RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}}","title":"Optimization"},{"location":"1. Basics/#gradient-descent","text":"Let's say we want to find the minimize a function, for example x^2 x^2 . We can easily find the minimum of this function (remember the second derivative rule in calculus?), but how can we do it for more complicated functions that are harder to differentiate like our objective function? This problem will get very hard , and very computationally intensive . To get over this hurdle of finding the exact minimum, we can instead approximate the minimum, using an algorithm called Gradient Descent . Imagine you have a ball and place it on a slope. It will move downwards, with the direction opposite of the gradient of the slope (remember the gradient is in the direction of ascent ). We can think of gradient descent as something similar. Here we will move our current approximation of the minimum, towards the gradient. When the gradient gets small enough (in other words, when the slope is near zero at a minimum) or when we have moved our approximation for enough epochs , then we set the current approximation as our final value. Illustration of Gradient Descent on 2D loss surface Moving down a 3D loss surface However, calculating the gradient of the cost function is a costly procedure, as it has to be done with each weight of your model. If we wanted to do this mathematically, we would have to calculate the equation below to find the derivative for each feature and each sample , which would kill any computer. \\frac{d}{{dx}}f\\left( x \\right) = \\mathop {\\lim }\\limits_{\\Delta \\to 0} \\frac{{f\\left( {x + \\Delta } \\right) - f\\left( x \\right)}}{\\Delta } \\frac{d}{{dx}}f\\left( x \\right) = \\mathop {\\lim }\\limits_{\\Delta \\to 0} \\frac{{f\\left( {x + \\Delta } \\right) - f\\left( x \\right)}}{\\Delta } Instead of doing that, let's simply define the gradient as the difference between our predictions from the current iteration of gradient descent and the true values, multiplied by our sample features. This will get an approximation of the change over each feature the loss. \\nabla f(X) = -X(values-predictions) \\nabla f(X) = -X(values-predictions) Here is psuedocode for Gradient Descent below, courtesy of CS231n: Gradient Descent Pseudocode 4 1 2 3 4 5 # Vanilla Gradient Descent while True : weights_grad = evaluate_gradient ( loss_fun , data , weights ) weights += - step_size * weights_grad # perform parameter update","title":"Gradient Descent"},{"location":"1. Basics/#stochastic-gradient-descent","text":"However, gradient descent has a huge drawback: it is computationally ineffecient . For every epoch, the gradient is calculated over all training samples. This is costly, and is unfeasible for most datasets. We can improve this by using Stochastic Gradient Descent (SGD) , a modification of the standard Gradient Descent algorithm. Stochastic Gradient Descent tries to solve the previous problem by only calculating the gradient for a single randomly sampled point at a time , hence the word Stochastic . Thus, this allows to update the weights of our model much quicker, allowing SGD to converge to a minima much quicker than in standard Gradient Descent. Although this optimization method is \"noisier\" it can often be much quicker to optimize a solution (illustrated below). We can reduce this use by calculating the gradient on batches of data instead of a single sample with Minibatch Gradient Descent . This can strike a balance can help reduce noise, but also allow us to still converge on our minima quickly. This noise is not always a negative trait though, as it can in fact possibly find us a more optimal solution for our regression. This additional noise can allow our solution to essentially \"hop out\" of local minima, allowing for the search of a more optimal minima. 5 This can be especially useful when you have a complicated loss landscape with many local minima, such as those for complicated neural networks 6 : Info Approximating the weights of this equation using SGD is one way to solve linear systems, but it is not the only way. One other method that may seem familiar to you is solving the closed form system of equations using linear algebra. I've linked this additional method in the Extras page .","title":"Stochastic Gradient Descent"},{"location":"1. Basics/#linear-regression-in-numpy","text":"Alright, let's finally do some coding! Go download the code from this repository, where you will recieve the starter code and As explained above, NumPy and Pandas are tools that every data scientist should know before they embark on solving a problem. In addition to these two, we will also use matplotlib in order to plot graphs related to the performance of our model! 1 2 3 import numpy as np import pandas as pd import matplotlib.pyplot as plt Let's also import our data as well. Load the csv into a dataframe using the function 1 pd . read_csv ( filename ) Info Definition: Dataframe One main feature of the Pandas library is the use of Dataframes. Dataframes make it very easy to filter through large datasets with different types of data. Think of Dataframes as 2D arrays where each element can have different types, or as a SQLite table that you store within your python program. Image of a dataframe that you should see in your Jupyter notebook when you import the data","title":"Linear Regression in Numpy"},{"location":"1. Basics/#data-preparation","text":"Before we start coding and creating our ML model, we have to do a fair bit of things to our data to ensure the best performance of our model. One major thing in our model is removing missing values in our data. Missing values can affect our function greatly, causing many of the mathematical functions we use to simply not work, so we should remove them! One example is when we are trying to evaluate our linear equation to predict housing values. When we are trying to calculate the prediction, if one feature is an NaN (not a number) in the dataset, we simply cannot compute the prediction! For example, for the linear equation below, when one of the values is a NaN , the output would obviously be NaN as well. w_1*NaN \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; NaN w_1*NaN \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_mx_m \\; = \\; NaN One way to get around this is to set these features that are missing to 0, but this essentially isn't true, so it is typically best practice to remove such samples that don't have a full feature set, just so these zero's don't affect our model too much. Some useful functions for this are the functions: 1 2 3 4 5 6 #Removes rows with NaN values in the dataframe your_dataframe . dropna () ''' Keep in mind that this functions doesn't edit the original dataframe in place, it returns another dataframe, so make sure to overwrite your dataframe or initialize a new one. ''' Another technique to help us ensure our model performs well is through Normalization of our data. What we mean by normalization is changing the features of our data in set ranges so that not one feature is inherently more important than another. One simple normalization method that we can use is min/max normalization. For this, we put all of our samples in the range of 0 to 1, with 1 being the maximum value of dataset for that feature. This makes our data less sensitive to things like the effect of units for each feature so that each can be weighed more evenly when creating weights for our linear equation. The equation for min/max normalization is given by Normalized\\: Sample = \\frac{Sample}{{Maximum\\: of\\: all\\: samples}} Normalized\\: Sample = \\frac{Sample}{{Maximum\\: of\\: all\\: samples}} 1 2 3 4 5 6 7 8 #TASK: Write a function to normalize all the data in the dataframe with min/max normalization def normalize_data ( df , columns ): #Empty dataframe normalized_df = pd . DataFrame () #ENTER CODE HERE return normalized_df Info Jargon Clarification: Performance This is one thing that is really confusing to a lot of people, how do I know whether my model performs well? The truth is, there isn't really a simple way to know this, and there is a lot of different ways to measure model performance. One way to measure model performance is the accuracy I highly recommend to read up on common machine learning performance metrics, but we will be using average absolute error and mean squared error for our regression, and accuracy for our classifications.","title":"Data Preparation"},{"location":"1. Basics/#initialization","text":"First, let's establish some numbers that we can use to modify the training of our linear regression model. These numbers are called hyperparameters Info Definition: Hyperparameters Hyperparameters define certain portions of your machine learning model, which allows you to customize certain portions of the training to get the best performance as possible. The main hyperparameters we will use during this workshop are the learning rate and the training steps Training steps are the number of times we will update our weights while we run gradient descent. For each training step of gradient descent, we will iterate through the entire dataset. Learning rate the the number that we will multiply our gradient by in each training step. This essentially allows us to decide how large each \"step\" our loss takes during each iteration of gradient descent. In order to find the best hyperparameters, one could do a \"grid search\" , where you could run your model over different combinations of your hyperparameters to get the set that has the best performance. Read more here: https://scikit-learn.org/stable/modules/grid_search.html Since hyperparameters don't matter too much for simple models like linear regression, let's just use something that looks fine. (Honestly a lot of machine learning is trying out different things and seeing if it works \ud83d\ude0a) 1 2 3 4 5 6 7 #Setting up hyperparameters \u200b #Alpha is our learning rate alpha = 0.1 \u200b #Iterations is how many times we will run our algorithm iterations = 10000","title":"Initialization"},{"location":"1. Basics/#training-our-model","text":"Now that we have set up our hyperparameters, we can now go over how to train our linear regression model using gradient descent. For this part of the workshop, we are going to create a function that takes in our data, labels, and hyperparameters, and outputs a model and a list containing the mean squared error for each training step. 1 def train ( x , y , training_steps , alpha ): Let's start by initializing our training. In our function, let's define some parameters of our function to ensure that everything works correctly. First, we will set up a history list to store our mean squared error for each iteration (you will see what this is used for later). In addition let's find the amount of weights that we need in addition to the length of our dataset. Functions: 1 2 your_np_array . shape #gets the shape of your python ndarray. #For example, for an nxm ndarray, this will return a tuple containing (n,m) Here is the skeleton code for this section to get you started on the structure 1 2 3 4 5 6 #Storing our cost function, Mean Squared Error history = [] #Finding the number of weights we need and also the number of samples num_weights = #Find the number of weights for n = #Find the number of samples in the dataset Next, let's initialize our weights! Let's initialize these weights randomly so that our model can converge to a minima with a more independent start. A useful function for this is the np.random.rand() function, which creates a list of random numbers. 1 2 3 #Initializing our weights to random numbers np . random . seed ( 69420 ) weights = #initialize weights Now that we have everything set up, I'll leave this part a bit more open ended, and write the pseudocode for each part of the gradient descent loop. For your convenience, here are the equations that are used in the gradient descent loop. Error = y - \\hat{y} Error = y - \\hat{y} \\hat{y} \\; = w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_nx_n \\hat{y} \\; = w_1x_1 \\; + \\; w_2x_2 \\; + \\; \\dots \\; + \\; w_nx_n \\nabla =(\\frac{1}{n})(y - \\hat{y})x \\nabla =(\\frac{1}{n})(y - \\hat{y})x RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} RMSE = \\sqrt{(\\frac{1}{2n})\\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})^{2}} 1 2 3 4 5 6 7 8 #iterating through each training step for i in range ( iterations ): #testing the model and find the error #finding the root mean square error of the current weights and then append it to our mse list #finding the gradient and then defining the new weights using this gradient return weights , history","title":"Training our Model"},{"location":"1. Basics/#testing-your-model","text":"Now that we have trained our model, let's see how our model performs in terms of fitting our data. Let's graph the RMSE which we stored for each training iteration of our gradient descent. Logically, the RMSE should decrease with each training step given our algorithm is working. You can use the code below to graph the RMSE that is returned from your train() function. 1 2 3 4 5 plt . title ( 'Root Mean Square Error (MSE) over each iteration' ) plt . xlabel ( 'No. of iterations' ) plt . ylabel ( 'RMSE' ) plt . plot ( history ) plt . show () We can also measure our final RMSE and average absolute error as well. We can simply take the dot product between the weights and a the inputs to make our predictions, and","title":"Testing your model"},{"location":"1. Basics/#linear-regression-binary-classifier","text":"Regression is continuous, so how can we turn this into something that is discrete. In other words, how can we go from our ML model predicting values, to predicting categories? In our case, how can we predict if a given sample is above a certain price? One simple way, is simply changing your prediction value from a continuous variable, to a discrete variable. In other words, we can simply change our y values from something that is continuous, to something that is categorical. We can apply a value of 1 for each \"true\" value, and a value of -1 for each \"false\" value. To get classifications after training our classifier, we can then simply get the sign of our output to receive a positive or negative classification Danger Although this is a simple way of creating a classifier, this isn't be best way to create such a classifier. Here is an example given by Andrew Ng: For the problem listed below, of classifying malignant tumors from tumor size, we can see below that the classifier can perform very well since we can simply say that those with a value above 0.5 are malignant, and those below 0.5 are not. However, what if we introduced an outlier sample that has an extremely large tumor size compared to previously malignant samples? Then we can definitely expect that this classifier would perform poorly. As the line that is fitted to our data would predict many of the tumors to be not malignant. This is one issue with using a linear regression model as a classifier, as it is fairly prone to outliers compared to other classification methods. There are many other ways to do such a classification, as we will be making these algorithms in the next workshop, where we get more into classification! One way of doing this is by using a logistic function, or by creating a hyperplane, such that the definition between malignant and nonmalignant is very clear. Source: Stackexchange In the future, we will go over multi-class classification problems (when you are trying to distinguish between more than 2 classes), but for now we will focus on binary classification.","title":"Linear Regression Binary Classifier"},{"location":"1. Basics/#conclusion","text":"So in conclusion, we learned a few things from this workshop What Regression is and how you can apply it to real world challenges Basics of optimization, including Gradient Descent and its modifications How classification models are made and how you can use them Python ndarrays vs. Lists https://webcourses.ucf.edu/courses/1249560/pages/python-lists-vs-numpy-arrays-what-is-the-difference \u21a9 Numpy Internals https://docs.scipy.org/doc/numpy-1.13.0/reference/internals.html \u21a9 Tensorflow Core C++ API https://www.tensorflow.org/api_docs/cc/group/core \u21a9 CS231n: Optimization http://cs231n.github.io/optimization-1/#optimization \u21a9 SGD and Local Minima https://leon.bottou.org/publications/pdf/nimes-1991.pdf \u21a9 Neural Network Loss Landscapes https://www.cs.umd.edu/~tomg/projects/landscapes/ \u21a9","title":"Conclusion"},{"location":"2. Classical ML and NLP/","text":"What is Classical Machine Learning? In this bootcamp, when we refer to Classical Machine Learning Algorithms, we simply mean algorithms that are not based on Deep Learning or Neural Network based learning methods. These algorithms have been used for decades, far before the current hype of Machine Learning and Artificial Intelligence . Some examples of Classical Machine Learning Algorithms include but are not limited to: Supervised Learning : Naive Bayes, Linear Regression, Logistic Regression, Ridge Regression, K Nearest Neighbors, Support Vector Machine Unsupervised Learning : Mean-shift, DBSCAN, K-Means Info DEFINITION DETOUR : Unsupervised and Supervised Learning Supervised : Supervised learning is unique in that it has training data. The model will learn from labeled data in order to predict something, usually in the form of classification or regression. Unsupervised : Unsupervised learning is when the algorithm attempts to create structure from unlabeled data. This is usually in the form of clustering, but can take other forms, such as learning representations of data. Since Classical Machine Learning Algorithms are often outclassed by Deep Learning algorthims, why should we even use them? The answer is more clear than you think. Simplicity . Classical Machine Learning Methods are often easier to explain and more computationally efficient that Deep Learning Based Approaches, allowing them to be deployed much easier and cheaper than their neural network-based counterparts. In addition, most classical algorithms run directly on the CPU, voiding the need for more costly GPU's. Perform Better with Less Data . Classical Machine Learning algorithms don't need as much data to get good predictions, and in many cases can perform better than neural networks with limited data. scikit-learn Scikit-learn includes off the shelf machine learning algorithms and tools, including all of the algorithms we are using in this workshop. Scikit-learn also includes many tools that we can use in our Natural Language processing workflows, simplifying a lot of our workflows. The Challenge You recently got fired from you job as a data scientist from your job as because they discovered that you lied on your resume and couldn't implement linear regression from scratch. You decide to pivot and work for a newspaper, who is trying to figure out the category of each news article to deliver tailored ads. In addition, they want to create a recommender system to recommend articles to readers. How do you do this? Click to Download Starter Code Click to Solution Code The Dataset The dataset that we are using is called the 20 Newsgroups Dataset which contains ~20,000 news documents spread across 20 different types of newsgroups. This dataset is made out of text documents, with each having a corresponding classification for each newsgroups, or category for each document. If given a new document, how can we predict what newsgroup it is in, and how can we find like documents as well? comp.graphics comp.os.ms-windows.misc comp.sys.ibm.pc.hardware comp.sys.mac.hardware comp.windows.x rec.autos rec.motorcycles rec.sport.baseball rec.sport.hockey sci.crypt sci.electronics sci.med sci.space misc.forsale talk.politics.misc talk.politics.guns talk.politics.mideast talk.religion.misc alt.atheism soc.religion.christian Classification and Clustering To complete the above task, we can use two basic tasks in machine learning - classification and clustering . The task of classification is simple, given a new sample, how can we classify what category this sample belongs to by using past data? In the previous workshop, we used regression, which was a supervised task, in which we had training data, which our algorithm used to create a line from which we can predict continuous values. We created labels , which was a category that each corresponding sample belonged to. However, instead of predicting the value of something given a sample, we want to tell whether this sample belongs to a classification or not. In general the goal of classification is to reduce our errors, or reduce the amount of times that our model will classify a sample incorrectly. We showed classification in the last workshop, where we classified our samples to predict whether these samples were over $200,000 or not, but in this workshop we will go a bit deeper and discuss different algorithms and methods that we can use to classify our datasets. Clustering is a bit different. For clustering, the goal is to take data and separate them into like groups. Clustering is a mainly unsupervised task where we simply group a dataset into clusters , where the samples within each cluster are most similar to each other. We will talk later about how we can decide whether the samples in these clusters are most similar to each other, but in general, these are used to separate data and find inherent differences in data without labels. Just as the last workshop, we can set the objective function for this task, as minimizing J_{clust} J_{clust} , where for each J for each cluster such that J_{clust} = J_{1} + J_{2} + \\cdots + J_{n} J_{clust} = J_{1} + J_{2} + \\cdots + J_{n} And each J_{n} J_{n} , given as J_{n} = (1/N) \\sum_{i \\in G_{j}}^{} \\|x_{i} - z_{j}\\| J_{n} = (1/N) \\sum_{i \\in G_{j}}^{} \\|x_{i} - z_{j}\\| Where, G_{j} G_{j} is each group, and z_{j} z_{j} is each of the group representatives, for each group with index j. Classifications and Clustering Algorithms Support Vector Machines Support Vector Machine, or SVM is a relatively new, yet powerful classifier. The workings of an SVM classifier is quite simple. It tries to create a hyperplane in the data space such that it can separate this entire space, with all samples on one side of the hyperplane as one class, and the samples on the other side of this hyperplane as the other class. To give a geometric representation, the hyperplane below can be illustrated in an \\mathbb{R}^2 \\mathbb{R}^2 and \\mathbb{R}^3 \\mathbb{R}^3 feature space. In \\mathbb{R}^2 \\mathbb{R}^2 , the hyperplane can be defined as a line, and above that a plane to denote the classification boundary in \\mathbb{R}^3 \\mathbb{R}^3 . Although we won't go to deep into the theory behind how we find this hyperplane, we will go a bit into how we find this hyperplane. Support Vector Machine gets its name from the support vectors that the algorithm includes. Support vectors are the points that lie closest to the hyperplane, and are therefore the most difficult to classify. The hyperplane is defined by this very small subset of these support vectors, and we want to maximize the margin between the support vectors and the hyperplane. This is given by an analogy of maximizing the street between the support vectors on each side of the hyperplane, where the edges of the street are defined by the support vectors, and the center of the street defined as the hyperplane. We can give the object function for the margin in that we want to maximize the margin from the hyperplane to the support vectors, where we can minimize the margin, maximize \\: \\frac{2}{{\\|w\\|}} maximize \\: \\frac{2}{{\\|w\\|}} Info What is the kernel trick? This is a common question asked in many ML interviews, and is fairly useful when trying to create a proper hyperplane. Essentially, the kernel trick is transforming your data to a higher dimension in order to create a hyperplane that can linearly separate the samples. For instance, in the image below, we obviously can't create a line that can intersect these data points to separate the two classes. But we can use a symmetric function, or kernel, to transform this data. The Radial Basis Function, or RBF, is commonly used as a kernel function in addition to Gaussian Filters as well. Learn more about kernel functions here 1 2 KMeans Wow, we were so into SVM classification that we almost forgot about the reccomender system. Lets try not to get that, as we definitely wouldn't want to get fired from this job as well. Let's start this problem by doing a quick case study on how recommender systems are typically implemented in industry, most notably how Netflix recommends content to its viewers. K-Means is a powerful heuristic that we can use to cluster our datasets. K-Means works all around its cluster representatives . Clusters are defined by the centroids, or center of each cluster with each sample being added to a cluster depending on the closest centroid to that respective sample. We can initialize kmeans by randomly selecting k points as our initial centroids, and then creating clusters based on the closest points to those centroids. We can then set the centroid to the average of all the points in the cluster, and then reiterate until the clusters do not change. K-means psuedocode given a list of N vectors [x_1 \\; \\cdots \\; x_N] [x_1 \\; \\cdots \\; x_N] and an initial list of k group representative vectors [z_1 \\; \\cdots \\; z_k] [z_1 \\; \\cdots \\; z_k] repeat until convergence: Partition the vectors into k groups. For each vector i = 1 ... N, assign x_i x_i to the group associated with the nearest representative. Update representatives. For each group j = 1 .. k, set z_j z_j to be the mean of the vectors in group j. Faq Question: How can you know what is a good number of clusters to split your data into? Just like the nature of K-Means, we can actually use another heuristic to find the correct value for k, also known as the elbow method . To do this, we can run K-means for different k-values, and plot the final J_{clust} J_{clust} value for each k. The graph should look like an angle with a large decrease in J_{clust} J_{clust} values, with the J_{clust} J_{clust} vlaues leveling off. This heuristic says that we should pick the k-value at the \"elbow\" of this angle, so we don't have too many clusters, but also not too little that our J_{clust} J_{clust} value is too high. Just keep in mind that we call this a heuristic because this algorithm won't always find the most optimal J_{clust} J_{clust} each time we run the algorithm. Depending on how K-Means is initialized, each time we cluster our dataset we will get different clusters. Faq What's the difference between K-Means and K-Nearest Neighbors? This is a pretty common question, and even a common interview question, as it's quite easy to confuse one with another, even though they really aren't similar at all. The only similarity between the two is one of the hyperparameters - K. In K-Means, k defines how many groups you want your data to be clustered into. K-Means as we have shown earlier is a clustering algorithm. On the other had, K-Nearest Neighbors is a voting-based classification algorithm. It works by taking the the k number of samples closest to the sample you are trying to classify. Using those K samples, the unknown sample is given the classification of the class with the most labels out of those K samples. In short, K-Means is an unsupervised classification model, while K-Nearest Neighbors is a supervised classification model. Natural Language Processing In the past workshop, we were dealing with almost exclusively numerical data. This made things pretty easy for us. This allowed us to put these numbers into vectors, which could easily work with our machine learning algorithms. However, with text data, if you wanted to use it with machine learning, we have to answer one main question How can we turn our text data into features that our machine learning model can use? More specifically, how can we derive computational methods to derive meaning or get analytics from text data? Natural Language Processing is a very broad field that intersects the field of machine learning greatly, but we will be using a few NLP methods to make high performing NLP Models. Feature Engineering and NLP Feature Engineering is the process of making Features from our data. Making proper features is essential for any Machine Learning workflow, especially for applications of NLP. Bag of Words One popular way to create proper features for NLP applications is by using the Bag of Words representation of text data. In bag of words, the order of words and grammar is unimportant, as we only care about the amount of times a words has appeared in a certain text. When using bag of words, a matrix would be created with every row is a specific word with the columns being the count of the word or other measurement. Essentially, the array is made of \"bins\" where each measurement is stored. For example, if we wanted to do a bag of words model with counts on this corpus (a corpus is essentially your full collection or dataset of text) This is the first document This document is the second document And this is the third one. Is this the first document? Your final bag of words representation using counts, or your Count Vectorizer , would look like this: and document first is one second the third this 0 1 1 1 0 0 1 0 1 0 2 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 Note You might think that when using the bag of words representation, you will be removing a lot of contextual and grammatical data about text . This is true, but for many large scale text applications such as the one we are doing here, specific grammar and other traits of sentences are irrelevant. For example, if you wanted to make your own version of the UCSD Spam Quarantine, you might find that many emails labeled as spam, would likely have very high frequency of certain words, likely \"buy\", \"free\", or other similar words. On the other hand, grammar might not be as important to the classification as certain words may be. However, this does not mean that not creating features from grammar is a bad idea, as it is very important in many subsections of NLP such as sentiment analysis and speech translation. TF-IDF On the other hand, using a count vectorizer isn't always the best method of creating a bag of words representation for your text . For example, what if one of your text samples is much longer than others which is the case for many datasets? Obviously the counts would be higher, but these words with higher counts would be weighed higher in your model, therefore causing this specific sample to skew your model. We can alter the count vectorization method by instead using a frequency method, where your bag of words representation is based on proportions instead of raw counts. The most common way to do this is through using term frequency - inverse document frequency method, or TF-IDF . Your term frequency can be calculated as: $$TF(t) = \\text{(# of times word t appears in a document) / (Total # of words in the document)} $$ IDF calculated as: $$ IDF(t) = \\text{log(Total # of documents / # of documents with word t in it)} $$ And you final TF-IDF for each word calculated as: TF(t) \\cdot IDF(t) TF(t) \\cdot IDF(t) Info Occam's razor You may have heard Occam's Razor before, which can be paraphrased as \"The simplest solution is most likely the right one.\" This saying can be true in any discipline in engineering, and is especially true with machine learning models. Higher complexity and unneeded features can cause your model to perform, worse, as yur model can start to weigh in these unnecessary features. Additional complexity to machine learning models also adds extra computational cost, meaning higher actual cost when your models are deployed. This reason is why data cleaning and reducing features is necessary to create well performing ML models. Always try to cut out complexity from your model NLP with sklearn Loading Data This part of the workshop is pretty easy compared to the last time in terms of importing data (last time was easy too, but this is even easier \ud83d\ude0a). sklearn includes some nice functions to load this dataset. Simply put, we can use the below functions to import the dataset and filter out extraneous data, such as the article headers and footers. After that, make sure to load this data into a dataframe to make use of the nice filtering functions in pandas. 1 2 from sklearn.datasets import fetch_20newsgroups newsgroups = fetch_20newsgroups ( subset = 'all' , remove = ( 'headers' , 'footers' , 'quotes' )) Data Cleaning In addition, when creating features from text, there may likely be words that add little to nothing to the meaning of a text, for example words like \"for\", \"and\", \"the\", or \"a\". We can remove these stopwords from our text to help clean our text from such useless features that can add to the complexity of our model. One library that we can use for this is nltk , which stands for N atural L anguage T ool k it We first have to download these stopwords, but with a bit of tricky use of the df.apply and lambda functions, we can remove these stop words from our data. 1 Dataframe . str . replace () In addition, for a lot of our text data, we want to remove extraneous symbols and other things that could affect our features. Feature Creation Now that we have removed unwanted text, let's now create features from our text data set. As explained earlier, we can use the bag of words representation with TF-IDF to create features that are independent of text size. This is done easily through TfidfVectorizer() in the sklearn.feature_extraction.text module. CS 229: Kernels https://see.stanford.edu/Course/CS229/39 \u21a9 Wikipedia: Kernel (Statistics) https://en.wikipedia.org/wiki/Kernel_(statistics) \u21a9","title":"2. Classical ML and NLP"},{"location":"2. Classical ML and NLP/#what-is-classical-machine-learning","text":"In this bootcamp, when we refer to Classical Machine Learning Algorithms, we simply mean algorithms that are not based on Deep Learning or Neural Network based learning methods. These algorithms have been used for decades, far before the current hype of Machine Learning and Artificial Intelligence . Some examples of Classical Machine Learning Algorithms include but are not limited to: Supervised Learning : Naive Bayes, Linear Regression, Logistic Regression, Ridge Regression, K Nearest Neighbors, Support Vector Machine Unsupervised Learning : Mean-shift, DBSCAN, K-Means Info DEFINITION DETOUR : Unsupervised and Supervised Learning Supervised : Supervised learning is unique in that it has training data. The model will learn from labeled data in order to predict something, usually in the form of classification or regression. Unsupervised : Unsupervised learning is when the algorithm attempts to create structure from unlabeled data. This is usually in the form of clustering, but can take other forms, such as learning representations of data. Since Classical Machine Learning Algorithms are often outclassed by Deep Learning algorthims, why should we even use them? The answer is more clear than you think. Simplicity . Classical Machine Learning Methods are often easier to explain and more computationally efficient that Deep Learning Based Approaches, allowing them to be deployed much easier and cheaper than their neural network-based counterparts. In addition, most classical algorithms run directly on the CPU, voiding the need for more costly GPU's. Perform Better with Less Data . Classical Machine Learning algorithms don't need as much data to get good predictions, and in many cases can perform better than neural networks with limited data.","title":"What is Classical Machine Learning?"},{"location":"2. Classical ML and NLP/#scikit-learn","text":"Scikit-learn includes off the shelf machine learning algorithms and tools, including all of the algorithms we are using in this workshop. Scikit-learn also includes many tools that we can use in our Natural Language processing workflows, simplifying a lot of our workflows.","title":"scikit-learn"},{"location":"2. Classical ML and NLP/#the-challenge","text":"You recently got fired from you job as a data scientist from your job as because they discovered that you lied on your resume and couldn't implement linear regression from scratch. You decide to pivot and work for a newspaper, who is trying to figure out the category of each news article to deliver tailored ads. In addition, they want to create a recommender system to recommend articles to readers. How do you do this? Click to Download Starter Code Click to Solution Code","title":"The Challenge"},{"location":"2. Classical ML and NLP/#the-dataset","text":"The dataset that we are using is called the 20 Newsgroups Dataset which contains ~20,000 news documents spread across 20 different types of newsgroups. This dataset is made out of text documents, with each having a corresponding classification for each newsgroups, or category for each document. If given a new document, how can we predict what newsgroup it is in, and how can we find like documents as well? comp.graphics comp.os.ms-windows.misc comp.sys.ibm.pc.hardware comp.sys.mac.hardware comp.windows.x rec.autos rec.motorcycles rec.sport.baseball rec.sport.hockey sci.crypt sci.electronics sci.med sci.space misc.forsale talk.politics.misc talk.politics.guns talk.politics.mideast talk.religion.misc alt.atheism soc.religion.christian","title":"The Dataset"},{"location":"2. Classical ML and NLP/#classification-and-clustering","text":"To complete the above task, we can use two basic tasks in machine learning - classification and clustering . The task of classification is simple, given a new sample, how can we classify what category this sample belongs to by using past data? In the previous workshop, we used regression, which was a supervised task, in which we had training data, which our algorithm used to create a line from which we can predict continuous values. We created labels , which was a category that each corresponding sample belonged to. However, instead of predicting the value of something given a sample, we want to tell whether this sample belongs to a classification or not. In general the goal of classification is to reduce our errors, or reduce the amount of times that our model will classify a sample incorrectly. We showed classification in the last workshop, where we classified our samples to predict whether these samples were over $200,000 or not, but in this workshop we will go a bit deeper and discuss different algorithms and methods that we can use to classify our datasets. Clustering is a bit different. For clustering, the goal is to take data and separate them into like groups. Clustering is a mainly unsupervised task where we simply group a dataset into clusters , where the samples within each cluster are most similar to each other. We will talk later about how we can decide whether the samples in these clusters are most similar to each other, but in general, these are used to separate data and find inherent differences in data without labels. Just as the last workshop, we can set the objective function for this task, as minimizing J_{clust} J_{clust} , where for each J for each cluster such that J_{clust} = J_{1} + J_{2} + \\cdots + J_{n} J_{clust} = J_{1} + J_{2} + \\cdots + J_{n} And each J_{n} J_{n} , given as J_{n} = (1/N) \\sum_{i \\in G_{j}}^{} \\|x_{i} - z_{j}\\| J_{n} = (1/N) \\sum_{i \\in G_{j}}^{} \\|x_{i} - z_{j}\\| Where, G_{j} G_{j} is each group, and z_{j} z_{j} is each of the group representatives, for each group with index j.","title":"Classification and Clustering"},{"location":"2. Classical ML and NLP/#classifications-and-clustering-algorithms","text":"","title":"Classifications and Clustering Algorithms"},{"location":"2. Classical ML and NLP/#support-vector-machines","text":"Support Vector Machine, or SVM is a relatively new, yet powerful classifier. The workings of an SVM classifier is quite simple. It tries to create a hyperplane in the data space such that it can separate this entire space, with all samples on one side of the hyperplane as one class, and the samples on the other side of this hyperplane as the other class. To give a geometric representation, the hyperplane below can be illustrated in an \\mathbb{R}^2 \\mathbb{R}^2 and \\mathbb{R}^3 \\mathbb{R}^3 feature space. In \\mathbb{R}^2 \\mathbb{R}^2 , the hyperplane can be defined as a line, and above that a plane to denote the classification boundary in \\mathbb{R}^3 \\mathbb{R}^3 . Although we won't go to deep into the theory behind how we find this hyperplane, we will go a bit into how we find this hyperplane. Support Vector Machine gets its name from the support vectors that the algorithm includes. Support vectors are the points that lie closest to the hyperplane, and are therefore the most difficult to classify. The hyperplane is defined by this very small subset of these support vectors, and we want to maximize the margin between the support vectors and the hyperplane. This is given by an analogy of maximizing the street between the support vectors on each side of the hyperplane, where the edges of the street are defined by the support vectors, and the center of the street defined as the hyperplane. We can give the object function for the margin in that we want to maximize the margin from the hyperplane to the support vectors, where we can minimize the margin, maximize \\: \\frac{2}{{\\|w\\|}} maximize \\: \\frac{2}{{\\|w\\|}} Info What is the kernel trick? This is a common question asked in many ML interviews, and is fairly useful when trying to create a proper hyperplane. Essentially, the kernel trick is transforming your data to a higher dimension in order to create a hyperplane that can linearly separate the samples. For instance, in the image below, we obviously can't create a line that can intersect these data points to separate the two classes. But we can use a symmetric function, or kernel, to transform this data. The Radial Basis Function, or RBF, is commonly used as a kernel function in addition to Gaussian Filters as well. Learn more about kernel functions here 1 2","title":"Support Vector Machines"},{"location":"2. Classical ML and NLP/#kmeans","text":"Wow, we were so into SVM classification that we almost forgot about the reccomender system. Lets try not to get that, as we definitely wouldn't want to get fired from this job as well. Let's start this problem by doing a quick case study on how recommender systems are typically implemented in industry, most notably how Netflix recommends content to its viewers. K-Means is a powerful heuristic that we can use to cluster our datasets. K-Means works all around its cluster representatives . Clusters are defined by the centroids, or center of each cluster with each sample being added to a cluster depending on the closest centroid to that respective sample. We can initialize kmeans by randomly selecting k points as our initial centroids, and then creating clusters based on the closest points to those centroids. We can then set the centroid to the average of all the points in the cluster, and then reiterate until the clusters do not change. K-means psuedocode given a list of N vectors [x_1 \\; \\cdots \\; x_N] [x_1 \\; \\cdots \\; x_N] and an initial list of k group representative vectors [z_1 \\; \\cdots \\; z_k] [z_1 \\; \\cdots \\; z_k] repeat until convergence: Partition the vectors into k groups. For each vector i = 1 ... N, assign x_i x_i to the group associated with the nearest representative. Update representatives. For each group j = 1 .. k, set z_j z_j to be the mean of the vectors in group j. Faq Question: How can you know what is a good number of clusters to split your data into? Just like the nature of K-Means, we can actually use another heuristic to find the correct value for k, also known as the elbow method . To do this, we can run K-means for different k-values, and plot the final J_{clust} J_{clust} value for each k. The graph should look like an angle with a large decrease in J_{clust} J_{clust} values, with the J_{clust} J_{clust} vlaues leveling off. This heuristic says that we should pick the k-value at the \"elbow\" of this angle, so we don't have too many clusters, but also not too little that our J_{clust} J_{clust} value is too high. Just keep in mind that we call this a heuristic because this algorithm won't always find the most optimal J_{clust} J_{clust} each time we run the algorithm. Depending on how K-Means is initialized, each time we cluster our dataset we will get different clusters. Faq What's the difference between K-Means and K-Nearest Neighbors? This is a pretty common question, and even a common interview question, as it's quite easy to confuse one with another, even though they really aren't similar at all. The only similarity between the two is one of the hyperparameters - K. In K-Means, k defines how many groups you want your data to be clustered into. K-Means as we have shown earlier is a clustering algorithm. On the other had, K-Nearest Neighbors is a voting-based classification algorithm. It works by taking the the k number of samples closest to the sample you are trying to classify. Using those K samples, the unknown sample is given the classification of the class with the most labels out of those K samples. In short, K-Means is an unsupervised classification model, while K-Nearest Neighbors is a supervised classification model.","title":"KMeans"},{"location":"2. Classical ML and NLP/#natural-language-processing","text":"In the past workshop, we were dealing with almost exclusively numerical data. This made things pretty easy for us. This allowed us to put these numbers into vectors, which could easily work with our machine learning algorithms. However, with text data, if you wanted to use it with machine learning, we have to answer one main question How can we turn our text data into features that our machine learning model can use? More specifically, how can we derive computational methods to derive meaning or get analytics from text data? Natural Language Processing is a very broad field that intersects the field of machine learning greatly, but we will be using a few NLP methods to make high performing NLP Models.","title":"Natural Language Processing"},{"location":"2. Classical ML and NLP/#feature-engineering-and-nlp","text":"Feature Engineering is the process of making Features from our data. Making proper features is essential for any Machine Learning workflow, especially for applications of NLP.","title":"Feature Engineering and NLP"},{"location":"2. Classical ML and NLP/#bag-of-words","text":"One popular way to create proper features for NLP applications is by using the Bag of Words representation of text data. In bag of words, the order of words and grammar is unimportant, as we only care about the amount of times a words has appeared in a certain text. When using bag of words, a matrix would be created with every row is a specific word with the columns being the count of the word or other measurement. Essentially, the array is made of \"bins\" where each measurement is stored. For example, if we wanted to do a bag of words model with counts on this corpus (a corpus is essentially your full collection or dataset of text) This is the first document This document is the second document And this is the third one. Is this the first document? Your final bag of words representation using counts, or your Count Vectorizer , would look like this: and document first is one second the third this 0 1 1 1 0 0 1 0 1 0 2 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 Note You might think that when using the bag of words representation, you will be removing a lot of contextual and grammatical data about text . This is true, but for many large scale text applications such as the one we are doing here, specific grammar and other traits of sentences are irrelevant. For example, if you wanted to make your own version of the UCSD Spam Quarantine, you might find that many emails labeled as spam, would likely have very high frequency of certain words, likely \"buy\", \"free\", or other similar words. On the other hand, grammar might not be as important to the classification as certain words may be. However, this does not mean that not creating features from grammar is a bad idea, as it is very important in many subsections of NLP such as sentiment analysis and speech translation.","title":"Bag of Words"},{"location":"2. Classical ML and NLP/#tf-idf","text":"On the other hand, using a count vectorizer isn't always the best method of creating a bag of words representation for your text . For example, what if one of your text samples is much longer than others which is the case for many datasets? Obviously the counts would be higher, but these words with higher counts would be weighed higher in your model, therefore causing this specific sample to skew your model. We can alter the count vectorization method by instead using a frequency method, where your bag of words representation is based on proportions instead of raw counts. The most common way to do this is through using term frequency - inverse document frequency method, or TF-IDF . Your term frequency can be calculated as: $$TF(t) = \\text{(# of times word t appears in a document) / (Total # of words in the document)} $$ IDF calculated as: $$ IDF(t) = \\text{log(Total # of documents / # of documents with word t in it)} $$ And you final TF-IDF for each word calculated as: TF(t) \\cdot IDF(t) TF(t) \\cdot IDF(t) Info Occam's razor You may have heard Occam's Razor before, which can be paraphrased as \"The simplest solution is most likely the right one.\" This saying can be true in any discipline in engineering, and is especially true with machine learning models. Higher complexity and unneeded features can cause your model to perform, worse, as yur model can start to weigh in these unnecessary features. Additional complexity to machine learning models also adds extra computational cost, meaning higher actual cost when your models are deployed. This reason is why data cleaning and reducing features is necessary to create well performing ML models. Always try to cut out complexity from your model","title":"TF-IDF"},{"location":"2. Classical ML and NLP/#nlp-with-sklearn","text":"","title":"NLP with sklearn"},{"location":"2. Classical ML and NLP/#loading-data","text":"This part of the workshop is pretty easy compared to the last time in terms of importing data (last time was easy too, but this is even easier \ud83d\ude0a). sklearn includes some nice functions to load this dataset. Simply put, we can use the below functions to import the dataset and filter out extraneous data, such as the article headers and footers. After that, make sure to load this data into a dataframe to make use of the nice filtering functions in pandas. 1 2 from sklearn.datasets import fetch_20newsgroups newsgroups = fetch_20newsgroups ( subset = 'all' , remove = ( 'headers' , 'footers' , 'quotes' ))","title":"Loading Data"},{"location":"2. Classical ML and NLP/#data-cleaning","text":"In addition, when creating features from text, there may likely be words that add little to nothing to the meaning of a text, for example words like \"for\", \"and\", \"the\", or \"a\". We can remove these stopwords from our text to help clean our text from such useless features that can add to the complexity of our model. One library that we can use for this is nltk , which stands for N atural L anguage T ool k it We first have to download these stopwords, but with a bit of tricky use of the df.apply and lambda functions, we can remove these stop words from our data. 1 Dataframe . str . replace () In addition, for a lot of our text data, we want to remove extraneous symbols and other things that could affect our features.","title":"Data Cleaning"},{"location":"2. Classical ML and NLP/#feature-creation","text":"Now that we have removed unwanted text, let's now create features from our text data set. As explained earlier, we can use the bag of words representation with TF-IDF to create features that are independent of text size. This is done easily through TfidfVectorizer() in the sklearn.feature_extraction.text module. CS 229: Kernels https://see.stanford.edu/Course/CS229/39 \u21a9 Wikipedia: Kernel (Statistics) https://en.wikipedia.org/wiki/Kernel_(statistics) \u21a9","title":"Feature Creation"},{"location":"3. Neural Networks and Computer Vision/","text":"What are Neural Networks In the past workshop, we talked about many of the weaknesses of neural networks, including their dependence on powerful computing and data. However, neural networks have one main advantage over classical machine learning methods: they can learn much more complex representations of your data than methods that we talked previously about can . In addition, when large amounts of feature rich data is available (such as with images), neural networks are not only the most logical method for tackling these problems, but the best. Neural Networks differ a lot compared to the past methods in that the inspiration is not mathematical, but biological. Neural networks operate in similar way to how neurons within our brain operate. Although neural networks are not exact copies of their biological counterparts (see Spiking Neural Networks below), we can approximate how they work to accomplish similar tasks. Here's a more in depth explanation of how Neural Networks work from a biological standpoint from Stanford University's CS231n : Each neuron receives input signals from its dendrites and produces output signals along its (single) axon. The axon eventually branches out and connects via synapses to dendrites of other neurons. In the computational model of a neuron, the signals that travel along the axons (e.g. x_{0} x_{0} ) interact multiplicatively (e.g. w_{0}x_{0} w_{0}x_{0} ) with the dendrites of the other neuron based on the synaptic strength at that synapse (e.g. w_{0} w_{0} ). The idea is that the synaptic strengths (the weights w w ) are learnable and control the strength of influence (and its direction: excitory (positive weight) or inhibitory (negative weight)) of one neuron on another. Thus, modeled from how neurons function in human brains, we can make models that are a bit more \"smart\" than those covered in the classical ML section. Just a preface on this workshop : The subject of neural networks is a very dense subject. Although the documentation for this section is the longest we have had yet, this barely scratches the surface of neural networks so don't feel dissuaded if this seems like an overwhelming amount of information. You can take entire courses on subjects that we spend 30 minutes on, so make sure that if certain subjects in this workshop interest you, make sure to do your own further research into neural networks. (Check out the Additional Resources page ) Computer Vision One of the best uses of Neural Networks and Deep Learning in general is Computer Vision . Computer Vision is a field of artificial intelligence that aims to develop algorithms and methods to complete tasks using images and video from the real world, and get analysis or inferences on this visual data. Computer Vision intersects many fields, including Machine Learning and Robotics, and is the basis for many groundbreaking technologies such as facial detection and self driving cars. Computer Vision is a good use case for Neural Networks, as Neural Networks are typically better at completing these more complicated tasks. Keras To code our Neural Networks within python, we will use a library called Keras . Keras is a library that makes it very easy to model and train deep neural networks within python. It simplifies the process of establishing neural network layers, and provides many convenience functions for things such as generating new data, training your model, and evaluating the performance of your models as well. Google Colab One question you might have is: \"How can I train neural networks with my 5 year old laptop without a GPU, or even worse ... a Mac? I heard that you need a beefy computer with a GPU to do these sort of things.\" And while that is a valid worry, and yes, you definitely need a powerful computer, but we will get around this using the cloud . More specifically, we will be using Google Colaboratory (or Colab for short), which is essentially a Jupyter Notebook running on Google Cloud Backend, which allows you to use their powerful CPU's and GPU's (or even a TPU for you weirdos), to run your code and train your models, without melting the bottom of your laptop. The Challenge: After the last terrible showing at your last job, you are now being forced to scour the world for any desperate attempt to make money. In your search through Craigslist ads, you find a man who will pay you to figure out ways to automate the sorting of his LEGO bricks (he's really lazy). So, in order to keep the lights on, you decide to dust off your machine learning toolkit to help him classify between different types of bricks. How can we use machine learning to classify and do inferences on images? The Dataset: To complete this task we obviously have to use past training data of imagery, so let's use a dataset related to the problem at hand: a dataset of LEGO bricks! The images in this dataset are artificially generated, meaning they are generated from 3D models rather than taking pictures of LEGOs with a camera, but they are images nonetheless and can prove to be useful in solving our problem. Link to Kaggle Dataset here Link to Starter Code here Basics: Perceptron When you first get into creating neural networks, things can get pretty confusing. Words like perceptron, activation function, and backpropagation can get pretty confusing. However, don't worry too much as we have actually already created the simplest case of a neural network: a perceptron. A perceptron functions as follows: The perceptron takes input features [x_{1} \\cdots x_{n}] [x_{1} \\cdots x_{n}] and multiplies each of the input features to each of it's corresponding weights [w_{1} \\cdots w_{n}] [w_{1} \\cdots w_{n}] for each feature Then, it sums up all of these weights multiplied by their inputs such that the output of this, y y is $$y = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + \\cdots + w_{4}x_{4} $$ (this is this starting to look familiar...) We then apply an activation function, h(x) h(x) ( also known as a transfer function for you EE majors ), to the weighted sum, to get our classification, \\hat{y} \\hat{y} . To match the diagram above, let's use a step function as our activation, outputting 0 for outputs below zero and, and 1 for ouputs above zero, such that h(x) = sign(x) = \\begin{cases} 0 & x < 0 \\\\ 1 & x\\geq 0 \\end{cases} h(x) = sign(x) = \\begin{cases} 0 & x < 0 \\\\ 1 & x\\geq 0 \\end{cases} With the final output prediction: $$ \\hat{y} = sign(w^{T}x) $$ This results in a loss function: \\frac{1}{N} \\sum_{i=1}^{N} max(0, -y_{i}w^{T}x_{i}) \\frac{1}{N} \\sum_{i=1}^{N} max(0, -y_{i}w^{T}x_{i}) This is exactly how we defined a linear regression classifier in the first workshop The linear single layer perceptron, therefore is simply our linear regression model, with an activation function at the end. In this case, the activation function is used to add a nonlinearity to our classification. In this case, we created a discrete nonlinearity, to create output labels for our classifications. In general for neural networks, these activation functions create non-linearities, which can allow our algorithms to model nonlinear functions , or do nonlinear classifications. Such example of nonlinear problems are the problems in which neural networks often tackle: tasks of speech recognition, financial analysis, and computer vision, problems that linear machine learning algorithms struggle to complete. Multi-Layer Perceprton (MLP) To continue on the last point, if we want to build on our perceptron, why not just once again, use the inspiration of a brain? Let's connect many neurons to each other, and see if it can classify. This is where the Multi-Layer Perceptron (MLP) comes in. A multilayer perceptron functions similarly to a standard perceptron, except it has more intermediate layers between the input and output, called hidden layers . These layers are called hidden layers simply because they are between the input and outputs, and are therefore \"hidden\" if you view the MLP from the outside. Standard linear perceptrons such as the one shown before are great for doing linear tasks, such as linear regression and classification, but Multi-Layer Perceptrons excel at fitting Non-linear datasets. In general a MLP contains 3 sections: Input Layer This simply takes in the inputs and feed them into the hidden layers of the network. Hidden Layers These are neurons where every neuron in a layer is connected to neurons in the layers in front of and behind that layer. MLP's can have as many hidden layers as you want to fit more complicated functions. However, note that with the more hidden layers your model has, the more prone your network is to overfitting (note below for more information about overfitting) Output Layers The output layer essentially does the opposite of what the input layer does, it takes all the outputs from the hidden layers, applies an activation function to get a final prediction value Backpropagation In order to get an output value for your MLP it's fairly easy. Just as in the single perceptron, we feed our inputs into the perceptron, and these weights are added and then pushed forward into the activation function. This is what's called a forward pass of the neural network, where calculations from the weights and neurons are passed forward. While it is easy to get an output value from a trained MLP, how can we actually train this model is fairly complicated, but works magically when implemented. Backpropagation works at the level of each individual neuron . For each neuron, with a given input, and a known output, we can calculate the gradient over that specific neuron with its individual input and output values. Since the specific mathematics of calculating these gradients can take an entire 2 hours in itself, we will save you the math (for now) and just show you that in order to start calculating these gradients, we need to do an entire forward pass through our neural network to calculate the gradient between the final neurons outputs and inputs. Using this gradient, we can recalculate weights, and move backwards throughout the neural network. See this figure below for an illustration on how backpropagation works. Attention Neural Networks are amazing universal approximators, in that they can approximate any function, linear or nonlinear. However, due to the nature of them being able to approximate any function, they can have a tendency to over-approximate a function as well. Let's say we take samples from an unknown wave, with the true wave being a simple sine wave. In the real world, when sampling a wave, there will be a bit of noise, oftentimes for waves gaussian white noise that comes along with your sample that makes normally distributed around the true values of your function. We can illustrate this in the figure below, with blue circles as our samples, and the green function as our true function, the sine wave. The model has obviously learned weights that make it fit the training data exactly. The function it generated passes through all the points, therefore we can expect the training error to be very low. On the other hand, this function is very far from the true sine wave, meaning we either need more data to avoid over fitting, or train our model enough where it can perform well on the training data, but generalize well to unseen data. Convolutional Neural Networks So you might ask, using things that we have previously talked about, how can we make an image classifier? For a simple example, we can just have each pixel be an input feature for the MLP. There is one weakness to this however: this method is insensitive to the position of objects in the image. Since each input pixel has an associated, single weight, this model doesn't account for movements of objects within the image. In addition, MLP's also only use pixels as their features, as apposed to shapes and other visual elements in an image. Convolutional Neural Networks aim to solve that issue. By sliding a window, or filter, across an image, the CNN then convolves the weights and outputs them to a feature map. It can use these convolutions to in fact learn how to extract notable features from images out of images (more on what we mean later). The Basic structure of a Convolutional Neural network is as follows: Feature Extraction Convolutional Layers to extract features from images Pooling Layers to take previous convolutional layers to a lower dimension Classification Dense Layers to classify using learned features Convolutional Layers Convolutional Layers, the Namesake of CNNS act as the feature recognition sections of CNN's. They act as a sliding window, taking a sliding window, and convolving with the pixels that the current filter is under by learned weights. This can be use to extract features out of images, as the filters it learns can effectively learn the spatial orientation of pixels without being dependent on position in image, because of the sliding window. Pooling Layers Pooling Layers are used to downsample convolutional layers down to a lower dimension. This allows the network to learn \"higher level\" features by allowing forward convolutional layers to learn from this downsampled data. Dense Layers Dense layers essentially act in a similar fashion to the hidden layers of a MLP. Much like how MLP's take input features from data and then classifies them, the Dense, or Fully Connected Layers takes features generated from the Convolutional layers and then classifies them using weights learned through backpropagation. Types of Activation Functions Although we talked previously about activation functions that add nonlinearities to your neural network, our CNN needs something similar to add nonlinearities in order to learn when to \"activate\" a neuron. Rectified Linear Unit (ReLU) The bread and butter activation function for CNN's and most neural networks is the **Rectified Linear Unit (ReLU) h(x) = max(0,x) h(x) = max(0,x) The ReLU activation function is one of the most commonly used activation functions in Deep Learning mainly because of it's simplicity. It is very cheap to compute the output of a ReLU activation, as it is simply just a boolean map, with it's derivative also being very easy to calculate ( max(0,1) max(0,1) ) TL;DR for ReLU: ReLU is an nonlinearity commonly used in Convolutional Neural Networks, that is simple and non computationally heavy. Sigmoid We will save you the math for the derivation of this, but Sigmoid activation functions are used to output the class probabilities , oftentimes in the final layer of the network, as you will see at the end of the CNN you construct. h(x) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x } } h(x) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x } } AlexNet AlexNet is one of the most groundbreaking CNN architectures, simply because it was one of the first to use multiple Convolotional Layers in series. This network changed the face of ILSVRC (we will talk more about this competition later), ushering a new era of Deep Learning supremacy in the field of image classification algorithms. Creating Neural Networks with Keras Let's start coding! First, let's make an implementation of AlexNet in Keras to complete our task to classify LEGOS If we take a step back to the past workshops, we followed a similar workflow for all image classification tasks. Clean Data Create Features Train Model Test Model In this workshop, we will follow a similar workflow as well to make our image classifier, which is based on the AlexNet architecture we talked about previously. Clean Data For this section, we can't really do much data cleaning. We can do some modifications to our images, but in general we don't want to change the images much. However, we can generate more images to simulate a larger dataset, which can be easily done with Keras. Let's make a new function that takes in certain parameters, and creates a generator for our training and validation data. 1 2 3 4 5 def generate_data ( train_data_dir , image_width , batch_size , aug ): #create generators here return train_generator , validation_generator Now let's actually make these generators. The first generator we will make is the ImageDataGenerator , which will set up the transformations we will add to the data. The image transformations we want to add is a horizontal shear, flipping the image vertically and horizontally, in addition to zooming in the image. For each image transformation we do, we can actually multiply our dataset, as a new training sample is made for each augmentation. See the figure below for example augmentations Now we can make the training and test generators for our data. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 train_generator = train_datagen . flow_from_directory ( train_data_dir , # Other arguments (fill these in) # # subset = 'training' , shuffle = True ) #Generate Validation data from images validation_generator = train_datagen . flow_from_directory ( train_data_dir , # same directory as training data # # # subset = 'validation' , shuffle = False ) Creating Features As we talked about before, Convolutional Neural Networks implicitly creates features from input images. With this stage, the CNN is doing all of the heavy lifting, but let's actually do this right now Let's set up the layer structure using the below chart for their respective filter sizes, stride, etc. We can create a function to make our model with the function returning the sequential model object that Keras created. 1 2 3 4 5 6 7 8 9 10 import keras from keras.layers import Dense , Activation , Dropout , Flatten , Conv2D , MaxPooling2D def create_alexnet (): model = keras . models . Sequential () model . add ( your layer ) #add layers according to the chart above return model To aid you in this, below we have some examples on adding new layers to your neural net: 1 2 3 4 5 6 7 8 9 10 11 12 13 #Example for input layer with 96 filters, a filter size of 11x11, with a stride of 4 and relu activation #we denote input shape since this is the input layer model . add ( Conv2D ( filters = 96 , input_shape = ( 224 , 224 , 3 ), kernel_size = ( 11 , 11 ), strides = ( 4 , 4 ), padding = 'valid' , activation = 'relu' )) #Example for MaxPooling2D Layer for a 2x2 size and a size 2 stride model . add ( MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = 'valid' )) #Flatten your the output matrix from your Conv2D Layers model . add ( Flatten ()) #Dense Layer with 9216 nodes and relu activation model . add ( Dense ( 9216 , activation = 'relu' )) After that we can create our model and generate our data 1 2 3 4 train_generator , validation_generator = generate_data ( train_data_dir , image_width , 64 , aug ) #Use create_alexnet() function to create network layer for AlexNet alexnet = create_alexnet () Train Model Now let's finally train our model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from keras.optimizers import SGD #Use stochastic gradient descent for optimizer opt = SGD ( lr = 0.01 , decay = 1e-6 , momentum = 0.9 , nesterov = True ) #Compile model with a categorical cross entropy loss and adam optimizer alexnet . compile ( loss = keras . losses . categorical_crossentropy , optimizer = opt , metrics = [ 'accuracy' ]) #Fit model and generate Data history = alexnet . fit_generator ( generator = train_generator , steps_per_epoch = 64 , validation_data = validation_generator , validation_steps = 64 , epochs = 20 ) Transfer Learning Let's get back to the challenge at hand. After your final accuracy of around 70 percent from the CNN you just made, that obviously isn't good enough to classify these LEGO bricks reliably. Your client is definitely going to encounter a bunch of Transfer Learning is the process of taking weights learned from a previous task, and using those previous weights to learn a new task. Think of the example from when we made a linear regression classifier with gradient descent. The weights that make up the slope of the line for linear regression for California housing prices are already at the local minimum learned from gradient descent. What if we wanted to train a linear regression model on Texas housing prices? Althogh the line fit doesn't have exactly the same slope and y-intercept, we can expect this California housing price line to be a lot closer than a random line to the line of best fit for This isn't too useful when dealing with simple models. As we saw before, it only takes a second to train our linear regression as we only had 8 weights that needed to be trained. However, what if we want to train models with millions of weights that need to be trained? By using previously trained weights that have been learned on relevant problems, we can expect our time and computing saved on training to be a lot higher, since the total amount of parameters that need to be trained have been reduced heavily. In short, Transfer Learning is used to save training time and computation, and in the case of CNN's, can be used to extract features when you don't have enough data to train the convolutional layers of your network. Attention One main negative point with transfer learning is that it is essentially a black box. Since we have no control over how the layers are being setup, and all aspects of the original neural network have to be followed such as relative sizes and things such as the optimizer and batch rates used. Be careful using transfer learning models, as many of these parameters are essntial to your CNN training at all . ImageNet ImageNet is not a Network Like much of the previous neural networks discussed, but in fact is a database with over 1 million images and 1000 classes aimed to be used in the ImageNet Large Scale Visual Recognition Challenge, where researchers attempt to make the highest accuracy image classifier. This dataset is used to benchmark many image classifiers, and is used greatly in transfer learning to train the Convolutional Layers in transfer learning problems. VGG16 VGG16 is an incremental improvement on AlexNet, being released shortly after. (It's essentially a deeper AlexNet with some other changes). VGG16 however is very heavy, and takes forever to train so why not use transfer learning to apply this better network to our problem. The process for Transfer Learning is similar, except instead of creating convolutional layers like we did with AlexNet, we can simply download the convolutional layers for VGG and add our own classification layers afterwards, loading VGG with the include_top = False argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 from keras.layers import Dense , Flatten , Dropout from keras import layers from keras.applications.vgg16 import VGG16 def create_vgg (): #Load VGG with imagenet weights vgg = VGG16 ( ###) #Freeze all layers of the original VGG model except for last 4 # Create the model model = keras . models . Sequential () # Add the vgg convolutional base model model . add ( vgg ) # Add new layers # Flatten output matrix # Fully Connected Layer with 1024 nodes and ReLU activation # Optional: Add dropout of 0.2 model . add ( Dropout ( 0.2 )) #Add dense layer with 16 ourputs and softmax activation return model We will then train the model with similar steps as what we did before, only with a different optimizer 1 2 3 4 5 6 7 8 9 10 11 from keras import optimizers #Compile VGG with RMSprop vgg . compile ( optimizer = optimizers . RMSprop ( lr = 1e-4 ), loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) #Retrain history = vgg . fit_generator ( ### ### ### )","title":"3. Neural Networks and Computer Vision"},{"location":"3. Neural Networks and Computer Vision/#what-are-neural-networks","text":"In the past workshop, we talked about many of the weaknesses of neural networks, including their dependence on powerful computing and data. However, neural networks have one main advantage over classical machine learning methods: they can learn much more complex representations of your data than methods that we talked previously about can . In addition, when large amounts of feature rich data is available (such as with images), neural networks are not only the most logical method for tackling these problems, but the best. Neural Networks differ a lot compared to the past methods in that the inspiration is not mathematical, but biological. Neural networks operate in similar way to how neurons within our brain operate. Although neural networks are not exact copies of their biological counterparts (see Spiking Neural Networks below), we can approximate how they work to accomplish similar tasks. Here's a more in depth explanation of how Neural Networks work from a biological standpoint from Stanford University's CS231n : Each neuron receives input signals from its dendrites and produces output signals along its (single) axon. The axon eventually branches out and connects via synapses to dendrites of other neurons. In the computational model of a neuron, the signals that travel along the axons (e.g. x_{0} x_{0} ) interact multiplicatively (e.g. w_{0}x_{0} w_{0}x_{0} ) with the dendrites of the other neuron based on the synaptic strength at that synapse (e.g. w_{0} w_{0} ). The idea is that the synaptic strengths (the weights w w ) are learnable and control the strength of influence (and its direction: excitory (positive weight) or inhibitory (negative weight)) of one neuron on another. Thus, modeled from how neurons function in human brains, we can make models that are a bit more \"smart\" than those covered in the classical ML section. Just a preface on this workshop : The subject of neural networks is a very dense subject. Although the documentation for this section is the longest we have had yet, this barely scratches the surface of neural networks so don't feel dissuaded if this seems like an overwhelming amount of information. You can take entire courses on subjects that we spend 30 minutes on, so make sure that if certain subjects in this workshop interest you, make sure to do your own further research into neural networks. (Check out the Additional Resources page )","title":"What are Neural Networks"},{"location":"3. Neural Networks and Computer Vision/#computer-vision","text":"One of the best uses of Neural Networks and Deep Learning in general is Computer Vision . Computer Vision is a field of artificial intelligence that aims to develop algorithms and methods to complete tasks using images and video from the real world, and get analysis or inferences on this visual data. Computer Vision intersects many fields, including Machine Learning and Robotics, and is the basis for many groundbreaking technologies such as facial detection and self driving cars. Computer Vision is a good use case for Neural Networks, as Neural Networks are typically better at completing these more complicated tasks.","title":"Computer Vision"},{"location":"3. Neural Networks and Computer Vision/#keras","text":"To code our Neural Networks within python, we will use a library called Keras . Keras is a library that makes it very easy to model and train deep neural networks within python. It simplifies the process of establishing neural network layers, and provides many convenience functions for things such as generating new data, training your model, and evaluating the performance of your models as well.","title":"Keras"},{"location":"3. Neural Networks and Computer Vision/#google-colab","text":"One question you might have is: \"How can I train neural networks with my 5 year old laptop without a GPU, or even worse ... a Mac? I heard that you need a beefy computer with a GPU to do these sort of things.\" And while that is a valid worry, and yes, you definitely need a powerful computer, but we will get around this using the cloud . More specifically, we will be using Google Colaboratory (or Colab for short), which is essentially a Jupyter Notebook running on Google Cloud Backend, which allows you to use their powerful CPU's and GPU's (or even a TPU for you weirdos), to run your code and train your models, without melting the bottom of your laptop.","title":"Google Colab"},{"location":"3. Neural Networks and Computer Vision/#the-challenge","text":"After the last terrible showing at your last job, you are now being forced to scour the world for any desperate attempt to make money. In your search through Craigslist ads, you find a man who will pay you to figure out ways to automate the sorting of his LEGO bricks (he's really lazy). So, in order to keep the lights on, you decide to dust off your machine learning toolkit to help him classify between different types of bricks. How can we use machine learning to classify and do inferences on images?","title":"The Challenge:"},{"location":"3. Neural Networks and Computer Vision/#the-dataset","text":"To complete this task we obviously have to use past training data of imagery, so let's use a dataset related to the problem at hand: a dataset of LEGO bricks! The images in this dataset are artificially generated, meaning they are generated from 3D models rather than taking pictures of LEGOs with a camera, but they are images nonetheless and can prove to be useful in solving our problem. Link to Kaggle Dataset here Link to Starter Code here","title":"The Dataset:"},{"location":"3. Neural Networks and Computer Vision/#basics-perceptron","text":"When you first get into creating neural networks, things can get pretty confusing. Words like perceptron, activation function, and backpropagation can get pretty confusing. However, don't worry too much as we have actually already created the simplest case of a neural network: a perceptron. A perceptron functions as follows: The perceptron takes input features [x_{1} \\cdots x_{n}] [x_{1} \\cdots x_{n}] and multiplies each of the input features to each of it's corresponding weights [w_{1} \\cdots w_{n}] [w_{1} \\cdots w_{n}] for each feature Then, it sums up all of these weights multiplied by their inputs such that the output of this, y y is $$y = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + \\cdots + w_{4}x_{4} $$ (this is this starting to look familiar...) We then apply an activation function, h(x) h(x) ( also known as a transfer function for you EE majors ), to the weighted sum, to get our classification, \\hat{y} \\hat{y} . To match the diagram above, let's use a step function as our activation, outputting 0 for outputs below zero and, and 1 for ouputs above zero, such that h(x) = sign(x) = \\begin{cases} 0 & x < 0 \\\\ 1 & x\\geq 0 \\end{cases} h(x) = sign(x) = \\begin{cases} 0 & x < 0 \\\\ 1 & x\\geq 0 \\end{cases} With the final output prediction: $$ \\hat{y} = sign(w^{T}x) $$ This results in a loss function: \\frac{1}{N} \\sum_{i=1}^{N} max(0, -y_{i}w^{T}x_{i}) \\frac{1}{N} \\sum_{i=1}^{N} max(0, -y_{i}w^{T}x_{i}) This is exactly how we defined a linear regression classifier in the first workshop The linear single layer perceptron, therefore is simply our linear regression model, with an activation function at the end. In this case, the activation function is used to add a nonlinearity to our classification. In this case, we created a discrete nonlinearity, to create output labels for our classifications. In general for neural networks, these activation functions create non-linearities, which can allow our algorithms to model nonlinear functions , or do nonlinear classifications. Such example of nonlinear problems are the problems in which neural networks often tackle: tasks of speech recognition, financial analysis, and computer vision, problems that linear machine learning algorithms struggle to complete.","title":"Basics: Perceptron"},{"location":"3. Neural Networks and Computer Vision/#multi-layer-perceprton-mlp","text":"To continue on the last point, if we want to build on our perceptron, why not just once again, use the inspiration of a brain? Let's connect many neurons to each other, and see if it can classify. This is where the Multi-Layer Perceptron (MLP) comes in. A multilayer perceptron functions similarly to a standard perceptron, except it has more intermediate layers between the input and output, called hidden layers . These layers are called hidden layers simply because they are between the input and outputs, and are therefore \"hidden\" if you view the MLP from the outside. Standard linear perceptrons such as the one shown before are great for doing linear tasks, such as linear regression and classification, but Multi-Layer Perceptrons excel at fitting Non-linear datasets. In general a MLP contains 3 sections: Input Layer This simply takes in the inputs and feed them into the hidden layers of the network. Hidden Layers These are neurons where every neuron in a layer is connected to neurons in the layers in front of and behind that layer. MLP's can have as many hidden layers as you want to fit more complicated functions. However, note that with the more hidden layers your model has, the more prone your network is to overfitting (note below for more information about overfitting) Output Layers The output layer essentially does the opposite of what the input layer does, it takes all the outputs from the hidden layers, applies an activation function to get a final prediction value","title":"Multi-Layer Perceprton (MLP)"},{"location":"3. Neural Networks and Computer Vision/#backpropagation","text":"In order to get an output value for your MLP it's fairly easy. Just as in the single perceptron, we feed our inputs into the perceptron, and these weights are added and then pushed forward into the activation function. This is what's called a forward pass of the neural network, where calculations from the weights and neurons are passed forward. While it is easy to get an output value from a trained MLP, how can we actually train this model is fairly complicated, but works magically when implemented. Backpropagation works at the level of each individual neuron . For each neuron, with a given input, and a known output, we can calculate the gradient over that specific neuron with its individual input and output values. Since the specific mathematics of calculating these gradients can take an entire 2 hours in itself, we will save you the math (for now) and just show you that in order to start calculating these gradients, we need to do an entire forward pass through our neural network to calculate the gradient between the final neurons outputs and inputs. Using this gradient, we can recalculate weights, and move backwards throughout the neural network. See this figure below for an illustration on how backpropagation works. Attention Neural Networks are amazing universal approximators, in that they can approximate any function, linear or nonlinear. However, due to the nature of them being able to approximate any function, they can have a tendency to over-approximate a function as well. Let's say we take samples from an unknown wave, with the true wave being a simple sine wave. In the real world, when sampling a wave, there will be a bit of noise, oftentimes for waves gaussian white noise that comes along with your sample that makes normally distributed around the true values of your function. We can illustrate this in the figure below, with blue circles as our samples, and the green function as our true function, the sine wave. The model has obviously learned weights that make it fit the training data exactly. The function it generated passes through all the points, therefore we can expect the training error to be very low. On the other hand, this function is very far from the true sine wave, meaning we either need more data to avoid over fitting, or train our model enough where it can perform well on the training data, but generalize well to unseen data.","title":"Backpropagation"},{"location":"3. Neural Networks and Computer Vision/#convolutional-neural-networks","text":"So you might ask, using things that we have previously talked about, how can we make an image classifier? For a simple example, we can just have each pixel be an input feature for the MLP. There is one weakness to this however: this method is insensitive to the position of objects in the image. Since each input pixel has an associated, single weight, this model doesn't account for movements of objects within the image. In addition, MLP's also only use pixels as their features, as apposed to shapes and other visual elements in an image. Convolutional Neural Networks aim to solve that issue. By sliding a window, or filter, across an image, the CNN then convolves the weights and outputs them to a feature map. It can use these convolutions to in fact learn how to extract notable features from images out of images (more on what we mean later). The Basic structure of a Convolutional Neural network is as follows: Feature Extraction Convolutional Layers to extract features from images Pooling Layers to take previous convolutional layers to a lower dimension Classification Dense Layers to classify using learned features","title":"Convolutional Neural Networks"},{"location":"3. Neural Networks and Computer Vision/#convolutional-layers","text":"Convolutional Layers, the Namesake of CNNS act as the feature recognition sections of CNN's. They act as a sliding window, taking a sliding window, and convolving with the pixels that the current filter is under by learned weights. This can be use to extract features out of images, as the filters it learns can effectively learn the spatial orientation of pixels without being dependent on position in image, because of the sliding window.","title":"Convolutional Layers"},{"location":"3. Neural Networks and Computer Vision/#pooling-layers","text":"Pooling Layers are used to downsample convolutional layers down to a lower dimension. This allows the network to learn \"higher level\" features by allowing forward convolutional layers to learn from this downsampled data.","title":"Pooling Layers"},{"location":"3. Neural Networks and Computer Vision/#dense-layers","text":"Dense layers essentially act in a similar fashion to the hidden layers of a MLP. Much like how MLP's take input features from data and then classifies them, the Dense, or Fully Connected Layers takes features generated from the Convolutional layers and then classifies them using weights learned through backpropagation.","title":"Dense Layers"},{"location":"3. Neural Networks and Computer Vision/#types-of-activation-functions","text":"Although we talked previously about activation functions that add nonlinearities to your neural network, our CNN needs something similar to add nonlinearities in order to learn when to \"activate\" a neuron.","title":"Types of Activation Functions"},{"location":"3. Neural Networks and Computer Vision/#rectified-linear-unit-relu","text":"The bread and butter activation function for CNN's and most neural networks is the **Rectified Linear Unit (ReLU) h(x) = max(0,x) h(x) = max(0,x) The ReLU activation function is one of the most commonly used activation functions in Deep Learning mainly because of it's simplicity. It is very cheap to compute the output of a ReLU activation, as it is simply just a boolean map, with it's derivative also being very easy to calculate ( max(0,1) max(0,1) ) TL;DR for ReLU: ReLU is an nonlinearity commonly used in Convolutional Neural Networks, that is simple and non computationally heavy.","title":"Rectified Linear Unit (ReLU)"},{"location":"3. Neural Networks and Computer Vision/#sigmoid","text":"We will save you the math for the derivation of this, but Sigmoid activation functions are used to output the class probabilities , oftentimes in the final layer of the network, as you will see at the end of the CNN you construct. h(x) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x } } h(x) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x } }","title":"Sigmoid"},{"location":"3. Neural Networks and Computer Vision/#alexnet","text":"AlexNet is one of the most groundbreaking CNN architectures, simply because it was one of the first to use multiple Convolotional Layers in series. This network changed the face of ILSVRC (we will talk more about this competition later), ushering a new era of Deep Learning supremacy in the field of image classification algorithms.","title":"AlexNet"},{"location":"3. Neural Networks and Computer Vision/#creating-neural-networks-with-keras","text":"Let's start coding! First, let's make an implementation of AlexNet in Keras to complete our task to classify LEGOS If we take a step back to the past workshops, we followed a similar workflow for all image classification tasks. Clean Data Create Features Train Model Test Model In this workshop, we will follow a similar workflow as well to make our image classifier, which is based on the AlexNet architecture we talked about previously.","title":"Creating Neural Networks with Keras"},{"location":"3. Neural Networks and Computer Vision/#clean-data","text":"For this section, we can't really do much data cleaning. We can do some modifications to our images, but in general we don't want to change the images much. However, we can generate more images to simulate a larger dataset, which can be easily done with Keras. Let's make a new function that takes in certain parameters, and creates a generator for our training and validation data. 1 2 3 4 5 def generate_data ( train_data_dir , image_width , batch_size , aug ): #create generators here return train_generator , validation_generator Now let's actually make these generators. The first generator we will make is the ImageDataGenerator , which will set up the transformations we will add to the data. The image transformations we want to add is a horizontal shear, flipping the image vertically and horizontally, in addition to zooming in the image. For each image transformation we do, we can actually multiply our dataset, as a new training sample is made for each augmentation. See the figure below for example augmentations Now we can make the training and test generators for our data. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 train_generator = train_datagen . flow_from_directory ( train_data_dir , # Other arguments (fill these in) # # subset = 'training' , shuffle = True ) #Generate Validation data from images validation_generator = train_datagen . flow_from_directory ( train_data_dir , # same directory as training data # # # subset = 'validation' , shuffle = False )","title":"Clean Data"},{"location":"3. Neural Networks and Computer Vision/#creating-features","text":"As we talked about before, Convolutional Neural Networks implicitly creates features from input images. With this stage, the CNN is doing all of the heavy lifting, but let's actually do this right now Let's set up the layer structure using the below chart for their respective filter sizes, stride, etc. We can create a function to make our model with the function returning the sequential model object that Keras created. 1 2 3 4 5 6 7 8 9 10 import keras from keras.layers import Dense , Activation , Dropout , Flatten , Conv2D , MaxPooling2D def create_alexnet (): model = keras . models . Sequential () model . add ( your layer ) #add layers according to the chart above return model To aid you in this, below we have some examples on adding new layers to your neural net: 1 2 3 4 5 6 7 8 9 10 11 12 13 #Example for input layer with 96 filters, a filter size of 11x11, with a stride of 4 and relu activation #we denote input shape since this is the input layer model . add ( Conv2D ( filters = 96 , input_shape = ( 224 , 224 , 3 ), kernel_size = ( 11 , 11 ), strides = ( 4 , 4 ), padding = 'valid' , activation = 'relu' )) #Example for MaxPooling2D Layer for a 2x2 size and a size 2 stride model . add ( MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = 'valid' )) #Flatten your the output matrix from your Conv2D Layers model . add ( Flatten ()) #Dense Layer with 9216 nodes and relu activation model . add ( Dense ( 9216 , activation = 'relu' )) After that we can create our model and generate our data 1 2 3 4 train_generator , validation_generator = generate_data ( train_data_dir , image_width , 64 , aug ) #Use create_alexnet() function to create network layer for AlexNet alexnet = create_alexnet ()","title":"Creating Features"},{"location":"3. Neural Networks and Computer Vision/#train-model","text":"Now let's finally train our model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from keras.optimizers import SGD #Use stochastic gradient descent for optimizer opt = SGD ( lr = 0.01 , decay = 1e-6 , momentum = 0.9 , nesterov = True ) #Compile model with a categorical cross entropy loss and adam optimizer alexnet . compile ( loss = keras . losses . categorical_crossentropy , optimizer = opt , metrics = [ 'accuracy' ]) #Fit model and generate Data history = alexnet . fit_generator ( generator = train_generator , steps_per_epoch = 64 , validation_data = validation_generator , validation_steps = 64 , epochs = 20 )","title":"Train Model"},{"location":"3. Neural Networks and Computer Vision/#transfer-learning","text":"Let's get back to the challenge at hand. After your final accuracy of around 70 percent from the CNN you just made, that obviously isn't good enough to classify these LEGO bricks reliably. Your client is definitely going to encounter a bunch of Transfer Learning is the process of taking weights learned from a previous task, and using those previous weights to learn a new task. Think of the example from when we made a linear regression classifier with gradient descent. The weights that make up the slope of the line for linear regression for California housing prices are already at the local minimum learned from gradient descent. What if we wanted to train a linear regression model on Texas housing prices? Althogh the line fit doesn't have exactly the same slope and y-intercept, we can expect this California housing price line to be a lot closer than a random line to the line of best fit for This isn't too useful when dealing with simple models. As we saw before, it only takes a second to train our linear regression as we only had 8 weights that needed to be trained. However, what if we want to train models with millions of weights that need to be trained? By using previously trained weights that have been learned on relevant problems, we can expect our time and computing saved on training to be a lot higher, since the total amount of parameters that need to be trained have been reduced heavily. In short, Transfer Learning is used to save training time and computation, and in the case of CNN's, can be used to extract features when you don't have enough data to train the convolutional layers of your network. Attention One main negative point with transfer learning is that it is essentially a black box. Since we have no control over how the layers are being setup, and all aspects of the original neural network have to be followed such as relative sizes and things such as the optimizer and batch rates used. Be careful using transfer learning models, as many of these parameters are essntial to your CNN training at all .","title":"Transfer Learning"},{"location":"3. Neural Networks and Computer Vision/#imagenet","text":"ImageNet is not a Network Like much of the previous neural networks discussed, but in fact is a database with over 1 million images and 1000 classes aimed to be used in the ImageNet Large Scale Visual Recognition Challenge, where researchers attempt to make the highest accuracy image classifier. This dataset is used to benchmark many image classifiers, and is used greatly in transfer learning to train the Convolutional Layers in transfer learning problems.","title":"ImageNet"},{"location":"3. Neural Networks and Computer Vision/#vgg16","text":"VGG16 is an incremental improvement on AlexNet, being released shortly after. (It's essentially a deeper AlexNet with some other changes). VGG16 however is very heavy, and takes forever to train so why not use transfer learning to apply this better network to our problem. The process for Transfer Learning is similar, except instead of creating convolutional layers like we did with AlexNet, we can simply download the convolutional layers for VGG and add our own classification layers afterwards, loading VGG with the include_top = False argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 from keras.layers import Dense , Flatten , Dropout from keras import layers from keras.applications.vgg16 import VGG16 def create_vgg (): #Load VGG with imagenet weights vgg = VGG16 ( ###) #Freeze all layers of the original VGG model except for last 4 # Create the model model = keras . models . Sequential () # Add the vgg convolutional base model model . add ( vgg ) # Add new layers # Flatten output matrix # Fully Connected Layer with 1024 nodes and ReLU activation # Optional: Add dropout of 0.2 model . add ( Dropout ( 0.2 )) #Add dense layer with 16 ourputs and softmax activation return model We will then train the model with similar steps as what we did before, only with a different optimizer 1 2 3 4 5 6 7 8 9 10 11 from keras import optimizers #Compile VGG with RMSprop vgg . compile ( optimizer = optimizers . RMSprop ( lr = 1e-4 ), loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) #Retrain history = vgg . fit_generator ( ### ### ### )","title":"VGG16"},{"location":"Additional Resources/","text":"Slideshows for Previous Workshops: Additional Machine Learning Resources if you are interested: Stanford Courses: These courses are taught by some of the world's most prevalent experts in machine learning, and include all information from lecture videos and notes to get you started. I highly reccomend these to those starting out. CS 230: Deep Learning - Stanford University CS 224N: Natural Language Processing with Deep Learning - Stanford University CS 231n: Convolutional Neural networks for Visual Recognition - Stanford University Online Courses Udacity Intro to Machine Learning fast.ai Practical Deep Learning for Coders Google Machine Learning Crash Course Machine Learning Videos sentdex ML tutorials Interview Prep: Machine Learning Flashcards","title":"Additional Resources"},{"location":"Additional Resources/#slideshows-for-previous-workshops","text":"","title":"Slideshows for Previous Workshops:"},{"location":"Additional Resources/#additional-machine-learning-resources-if-you-are-interested","text":"","title":"Additional Machine Learning Resources if you are interested:"},{"location":"Additional Resources/#stanford-courses","text":"These courses are taught by some of the world's most prevalent experts in machine learning, and include all information from lecture videos and notes to get you started. I highly reccomend these to those starting out. CS 230: Deep Learning - Stanford University CS 224N: Natural Language Processing with Deep Learning - Stanford University CS 231n: Convolutional Neural networks for Visual Recognition - Stanford University","title":"Stanford Courses:"},{"location":"Additional Resources/#online-courses","text":"Udacity Intro to Machine Learning fast.ai Practical Deep Learning for Coders Google Machine Learning Crash Course","title":"Online Courses"},{"location":"Additional Resources/#machine-learning-videos","text":"sentdex ML tutorials","title":"Machine Learning Videos"},{"location":"Additional Resources/#interview-prep","text":"Machine Learning Flashcards","title":"Interview Prep:"},{"location":"Extras/","text":"Workshop 1 - Linear Algebra Method of Solving the Problem of Least Squares Some of you may have asked, why would you use SGD when other methods for solving for least squares exist, such as simply finding the psuedoinverse? This is a very good question, as solving for the least squares problem can be easily done through the psuedoinverse. In the section below, I'll explain How you can use the psuedoinverse to find the weights of a linear least squares problem Why this method is in many cases can be worse than using SGD to find the weights. Bridging the Gap: Linear Algbra and Least Squares Let's get into the math of it. Say if we wanted to find the line between two points in a two dimensional space i.e. we only want to fit a line to two points in our dataset. This would be easy, simply solve the system of linear equations to find a line that intersects these two points. In other words, we can just row reduce the matrix below. rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22}\\end{bmatrix} = \\begin{bmatrix}w_{1} & 0\\\\0 & w_{2}\\end{bmatrix} rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22}\\end{bmatrix} = \\begin{bmatrix}w_{1} & 0\\\\0 & w_{2}\\end{bmatrix} or, solving for x, the parameters of the line which predicts y, is the following: x = A^{-1}y x = A^{-1}y Therefore, we can get a line such that mx = y What about if we have so many vectors that we aren't able to make a line that intersects these points, for example with the dataset we've shown above? Row reducing this matrix is impossible as the resulting augmented matrix will have free row variables, meaning there is no solution and the matrix is not invertible (Keep in mind that a matrix needs to be invertible in order to find x). rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22} \\\\a_{31} & a_{32} \\\\... & ... \\\\a_{n1} & a_{n2} \\end{bmatrix} rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22} \\\\a_{31} & a_{32} \\\\... & ... \\\\a_{n1} & a_{n2} \\end{bmatrix} This type of matrix is known as a tall, or overdetermined matrix. However, even though there is no exact solution because the matrix isn't invertible, that doesn't mean that there isn't an approximate solution that we can solve for. Psuedoinverse: Solving Overdetermined Matrices One way to solve for this is finding the psuedoinverse of the matrix to solve for the closest solution. The pseudoinverse is found with the following: We want to invert the right side in order to isolate x. If A was square, we could simply multiply both sides by the inverse of the original matrix to find our weights, x. However, we can make the matrix square through a simple algebraic transformation. We can multiply both sides by the matrix transposed, A^T A^T , such that A^TAx = A^Ty A^TAx = A^Ty We can then multiply both sides by the inverse of the new matrix on the left, (A^TA)^{-1} (A^TA)^{-1} such that x = (A^TA)^{-1}(A^TA)y x = (A^TA)^{-1}(A^TA)y This will get us the weights of the line, x, that can be used to predict values. Summary Just to give a bit of explanations for the variables we used above: \\hat{y} \\hat{y} : The predicted value that approximates y for an input sample y y : The true value for each sample that we are trying to predict A A : The input matrix. i.e. the features as the columns with each row being a single sample of your data. x x : The weights of the final approximate least squares equation","title":"Extras"},{"location":"Extras/#workshop-1-linear-algebra-method-of-solving-the-problem-of-least-squares","text":"Some of you may have asked, why would you use SGD when other methods for solving for least squares exist, such as simply finding the psuedoinverse? This is a very good question, as solving for the least squares problem can be easily done through the psuedoinverse. In the section below, I'll explain How you can use the psuedoinverse to find the weights of a linear least squares problem Why this method is in many cases can be worse than using SGD to find the weights.","title":"Workshop 1 - Linear Algebra Method of Solving the Problem of Least Squares"},{"location":"Extras/#bridging-the-gap-linear-algbra-and-least-squares","text":"Let's get into the math of it. Say if we wanted to find the line between two points in a two dimensional space i.e. we only want to fit a line to two points in our dataset. This would be easy, simply solve the system of linear equations to find a line that intersects these two points. In other words, we can just row reduce the matrix below. rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22}\\end{bmatrix} = \\begin{bmatrix}w_{1} & 0\\\\0 & w_{2}\\end{bmatrix} rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22}\\end{bmatrix} = \\begin{bmatrix}w_{1} & 0\\\\0 & w_{2}\\end{bmatrix} or, solving for x, the parameters of the line which predicts y, is the following: x = A^{-1}y x = A^{-1}y Therefore, we can get a line such that mx = y What about if we have so many vectors that we aren't able to make a line that intersects these points, for example with the dataset we've shown above? Row reducing this matrix is impossible as the resulting augmented matrix will have free row variables, meaning there is no solution and the matrix is not invertible (Keep in mind that a matrix needs to be invertible in order to find x). rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22} \\\\a_{31} & a_{32} \\\\... & ... \\\\a_{n1} & a_{n2} \\end{bmatrix} rref\\begin{bmatrix}a_{11} & a_{12}\\\\a_{21} & a_{22} \\\\a_{31} & a_{32} \\\\... & ... \\\\a_{n1} & a_{n2} \\end{bmatrix} This type of matrix is known as a tall, or overdetermined matrix. However, even though there is no exact solution because the matrix isn't invertible, that doesn't mean that there isn't an approximate solution that we can solve for.","title":"Bridging the Gap: Linear Algbra and Least Squares"},{"location":"Extras/#psuedoinverse-solving-overdetermined-matrices","text":"One way to solve for this is finding the psuedoinverse of the matrix to solve for the closest solution. The pseudoinverse is found with the following: We want to invert the right side in order to isolate x. If A was square, we could simply multiply both sides by the inverse of the original matrix to find our weights, x. However, we can make the matrix square through a simple algebraic transformation. We can multiply both sides by the matrix transposed, A^T A^T , such that A^TAx = A^Ty A^TAx = A^Ty We can then multiply both sides by the inverse of the new matrix on the left, (A^TA)^{-1} (A^TA)^{-1} such that x = (A^TA)^{-1}(A^TA)y x = (A^TA)^{-1}(A^TA)y This will get us the weights of the line, x, that can be used to predict values. Summary Just to give a bit of explanations for the variables we used above: \\hat{y} \\hat{y} : The predicted value that approximates y for an input sample y y : The true value for each sample that we are trying to predict A A : The input matrix. i.e. the features as the columns with each row being a single sample of your data. x x : The weights of the final approximate least squares equation","title":"Psuedoinverse: Solving Overdetermined Matrices"}]}